{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt selection and testing\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, compare_request_configurations\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "from helper_functions import files_to_df_func, files_to_df_core_func\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dev_data_folder = 'data/dev_data'\n",
    "dev_transcripts = os.path.join(dev_data_folder, 'dev_data_transcript')\n",
    "dev_raw_ocr_folder =  os.path.join(dev_data_folder,'dev_raw_ocr' )\n",
    "dev_system_message_folder = os.path.join(dev_data_folder,'dev_system_message_variants' )\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv(os.path.join(dev_data_folder,'dev_data_raw.csv'))\n",
    "\n",
    "\n",
    "#for saving data to be used in the analysis\n",
    "if not os.path.exists('data/analysis'):\n",
    "    os.makedirs('data/analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different system prompts\n",
    "\n",
    "This explores a range of system prompt to find the one that appears to work the best, we use gpt4 as the baseline model.\n",
    "\n",
    "Although there is no comparison with all models we do test gpt3.5 gpt4, clause haiku and claude opus, in addition we put the prompt in the system message and the prompt after the text becuase this may affect the quality of the result. When the prompt is after the text the response has \"nosm_\" (no system message) appended to the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a modular set of system messages that can be combined in different ways\n",
    "basic_prompt = \"Please recover the text from the corrupted OCR.\"\n",
    "expertise_prompt = \"You are an expert in post-OCR correction of documents.\"\n",
    "recover_prompt = \"Using the context available from the text please recover the most likely original text from the corrupted OCR.\"\n",
    "publication_context_prompt = \"The text is from an english newspaper in the 1800's.\"\n",
    "text_context_prompt = \"The text may be an advert or article and may be missing the beggining or end.\"\n",
    "additional_instructions_prompt = \"Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\n",
    "\n",
    "#combine all the message parts into a variety of system messages, a tuple is used where 0 is the name of the message and 1 is the message itself\n",
    "#N.B. This is not and exhaustive combination as that would be very expensive and likley not yield significantly better results\n",
    "system_messages_list = [\n",
    "('basic_prompt', basic_prompt),\n",
    "('expert_basic_prompt', expertise_prompt + ' '+ basic_prompt),\n",
    "('expert_recover_prompt', expertise_prompt + ' '+ recover_prompt),\n",
    "('expert_recover_publication_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt),\n",
    "('expert_recover_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_publication_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_instructions_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + additional_instructions_prompt),\n",
    "('full_context_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt+ ' ' + additional_instructions_prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function is used to make the creation of the config dictionaries for the test more compact and increase readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_test_configs(system_messages_list, get_response_func, engine):\n",
    "    message_test_configs = []\n",
    "    for iter_system_message in system_messages_list:\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=iter_system_message[1],\n",
    "                prompt_template=\"{content_html}\",\n",
    "                additional_args={'response_name': iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=\"\",\n",
    "                prompt_template=\"{content_html}\" + f\"\"\"\\n\\n\"\"\" + iter_system_message[1],\n",
    "                additional_args={'response_name': \"nosm_\"+iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "    return message_test_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs and run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt configs\n",
    "gpt3_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, \"gpt-3.5-turbo\")\n",
    "gpt4_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, 'gpt-4-turbo-preview')\n",
    "\n",
    "#claude configs\n",
    "haiku_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-haiku-20240307\")\n",
    "opus_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-opus-20240229\")\n",
    "\n",
    "#run the experiment on all the prompt configs and save to the folder\n",
    "compare_request_configurations(dev_data_df, \n",
    "                               gpt3_prompt_testing_configs + gpt4_prompt_testing_configs + haiku_prompt_testing_configs + opus_prompt_testing_configs,\n",
    "                               folder_path = dev_system_message_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_test_df = []\n",
    "for folder in os.listdir(dev_system_message_folder):\n",
    "    df = files_to_df_core_func(dev_system_message_folder)\n",
    "    df['folder'] = folder\n",
    "    prompt_test_df.append(df)\n",
    "\n",
    "prompt_test_df = pd.concat(prompt_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_ocr_scores = evaluate_correction_performance(dev_raw_ocr_folder , dev_transcripts, wer, cer, 'raw_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = dev_system_message_folder\n",
    "\n",
    "performance_eval = evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt'),:]\n",
    "\n",
    "performance_eval['type'] = performance_eval['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "\n",
    "performance_eval['model'] = performance_eval['type'].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_haiku</th>\n",
       "      <td>-4.66</td>\n",
       "      <td>8.18</td>\n",
       "      <td>-296.51</td>\n",
       "      <td>-197.56</td>\n",
       "      <td>-283.62</td>\n",
       "      <td>-181.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_haiku</th>\n",
       "      <td>2.83</td>\n",
       "      <td>12.73</td>\n",
       "      <td>-294.84</td>\n",
       "      <td>-152.04</td>\n",
       "      <td>-281.51</td>\n",
       "      <td>-147.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_haiku</th>\n",
       "      <td>16.26</td>\n",
       "      <td>31.82</td>\n",
       "      <td>-209.72</td>\n",
       "      <td>-115.22</td>\n",
       "      <td>-200.48</td>\n",
       "      <td>-110.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_haiku</th>\n",
       "      <td>0.41</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-297.10</td>\n",
       "      <td>-106.33</td>\n",
       "      <td>-283.08</td>\n",
       "      <td>-103.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_haiku</th>\n",
       "      <td>37.93</td>\n",
       "      <td>45.61</td>\n",
       "      <td>-90.47</td>\n",
       "      <td>-38.91</td>\n",
       "      <td>-86.93</td>\n",
       "      <td>-40.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>73.21</td>\n",
       "      <td>77.19</td>\n",
       "      <td>54.38</td>\n",
       "      <td>63.78</td>\n",
       "      <td>51.48</td>\n",
       "      <td>62.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_pub_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.88</td>\n",
       "      <td>78.71</td>\n",
       "      <td>40.15</td>\n",
       "      <td>68.74</td>\n",
       "      <td>37.37</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.74</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.40</td>\n",
       "      <td>68.74</td>\n",
       "      <td>54.51</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.91</td>\n",
       "      <td>81.03</td>\n",
       "      <td>46.22</td>\n",
       "      <td>65.41</td>\n",
       "      <td>42.21</td>\n",
       "      <td>63.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>72.10</td>\n",
       "      <td>75.86</td>\n",
       "      <td>49.29</td>\n",
       "      <td>65.55</td>\n",
       "      <td>46.21</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER            CER  \\\n",
       "                                                     mean    50%    mean   \n",
       "type                                                                       \n",
       "expert_recover_text_prompt_haiku                    -4.66   8.18 -296.51   \n",
       "nosm_expert_recover_publication_text_prompt_haiku    2.83  12.73 -294.84   \n",
       "expert_recover_publication_text_prompt_haiku        16.26  31.82 -209.72   \n",
       "nosm_expert_recover_text_prompt_haiku                0.41   7.50 -297.10   \n",
       "expert_recover_prompt_haiku                         37.93  45.61  -90.47   \n",
       "...                                                   ...    ...     ...   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview        73.21  77.19   54.38   \n",
       "nosm_expert_recover_pub_instructions_prompt_cla...  71.88  78.71   40.15   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     72.74  80.46   58.40   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  72.91  81.03   46.22   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview      72.10  75.86   49.29   \n",
       "\n",
       "                                                           lev_dist          \n",
       "                                                       50%     mean     50%  \n",
       "type                                                                         \n",
       "expert_recover_text_prompt_haiku                   -197.56  -283.62 -181.11  \n",
       "nosm_expert_recover_publication_text_prompt_haiku  -152.04  -281.51 -147.84  \n",
       "expert_recover_publication_text_prompt_haiku       -115.22  -200.48 -110.20  \n",
       "nosm_expert_recover_text_prompt_haiku              -106.33  -283.08 -103.45  \n",
       "expert_recover_prompt_haiku                         -38.91   -86.93  -40.09  \n",
       "...                                                    ...      ...     ...  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview         63.78    51.48   62.23  \n",
       "nosm_expert_recover_pub_instructions_prompt_cla...   68.74    37.37   62.84  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229      68.74    54.51   62.84  \n",
       "expert_recover_instructions_prompt_claude-3-opu...   65.41    42.21   63.30  \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview       65.55    46.21   63.79  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>55.27</td>\n",
       "      <td>74.37</td>\n",
       "      <td>-30.47</td>\n",
       "      <td>43.74</td>\n",
       "      <td>-33.26</td>\n",
       "      <td>40.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.07</td>\n",
       "      <td>73.90</td>\n",
       "      <td>44.04</td>\n",
       "      <td>50.23</td>\n",
       "      <td>39.63</td>\n",
       "      <td>45.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.36</td>\n",
       "      <td>76.02</td>\n",
       "      <td>49.85</td>\n",
       "      <td>57.28</td>\n",
       "      <td>45.44</td>\n",
       "      <td>46.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>69.83</td>\n",
       "      <td>72.41</td>\n",
       "      <td>46.73</td>\n",
       "      <td>52.74</td>\n",
       "      <td>42.14</td>\n",
       "      <td>47.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.06</td>\n",
       "      <td>76.88</td>\n",
       "      <td>48.80</td>\n",
       "      <td>53.71</td>\n",
       "      <td>44.31</td>\n",
       "      <td>51.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>62.40</td>\n",
       "      <td>73.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>56.11</td>\n",
       "      <td>2.23</td>\n",
       "      <td>51.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_pub_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>74.58</td>\n",
       "      <td>78.89</td>\n",
       "      <td>57.67</td>\n",
       "      <td>66.22</td>\n",
       "      <td>52.95</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.00</td>\n",
       "      <td>74.37</td>\n",
       "      <td>41.13</td>\n",
       "      <td>55.14</td>\n",
       "      <td>36.57</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.19</td>\n",
       "      <td>72.41</td>\n",
       "      <td>43.40</td>\n",
       "      <td>56.22</td>\n",
       "      <td>38.97</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>69.84</td>\n",
       "      <td>74.14</td>\n",
       "      <td>41.57</td>\n",
       "      <td>57.01</td>\n",
       "      <td>37.36</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>67.83</td>\n",
       "      <td>78.89</td>\n",
       "      <td>24.82</td>\n",
       "      <td>56.56</td>\n",
       "      <td>22.79</td>\n",
       "      <td>53.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.42</td>\n",
       "      <td>75.86</td>\n",
       "      <td>41.21</td>\n",
       "      <td>57.01</td>\n",
       "      <td>37.20</td>\n",
       "      <td>53.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.86</td>\n",
       "      <td>77.59</td>\n",
       "      <td>55.84</td>\n",
       "      <td>61.46</td>\n",
       "      <td>50.93</td>\n",
       "      <td>56.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>75.14</td>\n",
       "      <td>79.57</td>\n",
       "      <td>58.65</td>\n",
       "      <td>64.39</td>\n",
       "      <td>53.70</td>\n",
       "      <td>59.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.45</td>\n",
       "      <td>81.03</td>\n",
       "      <td>55.15</td>\n",
       "      <td>66.83</td>\n",
       "      <td>50.36</td>\n",
       "      <td>61.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_pub_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.88</td>\n",
       "      <td>78.71</td>\n",
       "      <td>40.15</td>\n",
       "      <td>68.74</td>\n",
       "      <td>37.37</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.74</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.40</td>\n",
       "      <td>68.74</td>\n",
       "      <td>54.51</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.91</td>\n",
       "      <td>81.03</td>\n",
       "      <td>46.22</td>\n",
       "      <td>65.41</td>\n",
       "      <td>42.21</td>\n",
       "      <td>63.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER           CER  \\\n",
       "                                                     mean    50%   mean   \n",
       "type                                                                      \n",
       "nosm_expert_recover_publication_text_prompt_cla...  55.27  74.37 -30.47   \n",
       "nosm_expert_recover_publication_prompt_claude-3...  71.07  73.90  44.04   \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  70.36  76.02  49.85   \n",
       "nosm_basic_prompt_claude-3-opus-20240229            69.83  72.41  46.73   \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   72.06  76.88  48.80   \n",
       "expert_recover_prompt_claude-3-opus-20240229        62.40  73.90   4.22   \n",
       "expert_recover_pub_instructions_prompt_claude-3...  74.58  78.89  57.67   \n",
       "expert_recover_publication_prompt_claude-3-opus...  70.00  74.37  41.13   \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   71.19  72.41  43.40   \n",
       "expert_recover_publication_text_prompt_claude-3...  69.84  74.14  41.57   \n",
       "full_context_prompt_claude-3-opus-20240229          67.83  78.89  24.82   \n",
       "basic_prompt_claude-3-opus-20240229                 71.42  75.86  41.21   \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     72.86  77.59  55.84   \n",
       "expert_basic_prompt_claude-3-opus-20240229          75.14  79.57  58.65   \n",
       "nosm_expert_recover_instructions_prompt_claude-...  73.45  81.03  55.15   \n",
       "nosm_expert_recover_pub_instructions_prompt_cla...  71.88  78.71  40.15   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     72.74  80.46  58.40   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  72.91  81.03  46.22   \n",
       "\n",
       "                                                          lev_dist         \n",
       "                                                      50%     mean    50%  \n",
       "type                                                                       \n",
       "nosm_expert_recover_publication_text_prompt_cla...  43.74   -33.26  40.25  \n",
       "nosm_expert_recover_publication_prompt_claude-3...  50.23    39.63  45.26  \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  57.28    45.44  46.78  \n",
       "nosm_basic_prompt_claude-3-opus-20240229            52.74    42.14  47.06  \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   53.71    44.31  51.41  \n",
       "expert_recover_prompt_claude-3-opus-20240229        56.11     2.23  51.65  \n",
       "expert_recover_pub_instructions_prompt_claude-3...  66.22    52.95  51.72  \n",
       "expert_recover_publication_prompt_claude-3-opus...  55.14    36.57  51.72  \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   56.22    38.97  51.72  \n",
       "expert_recover_publication_text_prompt_claude-3...  57.01    37.36  53.19  \n",
       "full_context_prompt_claude-3-opus-20240229          56.56    22.79  53.29  \n",
       "basic_prompt_claude-3-opus-20240229                 57.01    37.20  53.62  \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     61.46    50.93  56.68  \n",
       "expert_basic_prompt_claude-3-opus-20240229          64.39    53.70  59.45  \n",
       "nosm_expert_recover_instructions_prompt_claude-...  66.83    50.36  61.12  \n",
       "nosm_expert_recover_pub_instructions_prompt_cla...  68.74    37.37  62.84  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     68.74    54.51  62.84  \n",
       "expert_recover_instructions_prompt_claude-3-opu...  65.41    42.21  63.30  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['type'].str.contains('opus')].groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>148.62</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>151.38</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_pub_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>153.43</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>183.24</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>160.43</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>438.71</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>581.00</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>785.76</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>630.95</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.54</td>\n",
       "      <td>605.81</td>\n",
       "      <td>575.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            WER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.23   \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.23   \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview     0.23   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.24   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.24   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.59   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.72   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.84   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.82   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.82   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.15   \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview     0.14   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.19   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.16   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.53   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.51   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.90   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.81   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.68   \n",
       "\n",
       "                                                                            CER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.13   \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview     0.13   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.14   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.14   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.44   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.58   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.68   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.64   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.66   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.06   \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.06   \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview     0.05   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.05   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.07   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.42   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.41   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.70   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.65   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.54   \n",
       "\n",
       "                                                                          lev_dist  \\\n",
       "                                                                              mean   \n",
       "type                                               model                             \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      148.62   \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      151.38   \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview      153.43   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   183.24   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      160.43   \n",
       "...                                                                            ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                    438.71   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                    581.00   \n",
       "expert_recover_text_prompt_haiku                   haiku                    785.76   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                    630.95   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                    605.81   \n",
       "\n",
       "                                                                                  \n",
       "                                                                             50%  \n",
       "type                                               model                          \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      77.0  \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      80.0  \n",
       "expert_recover_pub_instructions_prompt_gpt-4-tu... gpt-4-turbo-preview      80.0  \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   84.0  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      87.0  \n",
       "...                                                                          ...  \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   396.0  \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   526.0  \n",
       "expert_recover_text_prompt_haiku                   haiku                   543.0  \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   549.0  \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   575.0  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "#performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">claude-3-opus-20240229</th>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>expert_recover_publication_text_prompt_gpt-3.5-turbo</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_gpt-3.5-turbo</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4-turbo-preview</th>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_pub_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">haiku</th>\n",
       "      <th>expert_recover_instructions_prompt_haiku</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_pub_instructions_prompt_haiku</th>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           lev_dist\n",
       "model                  type                                                        \n",
       "claude-3-opus-20240229 expert_recover_instructions_prompt_claude-3-opu...      84.0\n",
       "                       nosm_full_context_prompt_claude-3-opus-20240229         87.0\n",
       "gpt-3.5-turbo          expert_recover_publication_text_prompt_gpt-3.5-...     111.0\n",
       "                       expert_recover_publication_prompt_gpt-3.5-turbo        111.0\n",
       "gpt-4-turbo-preview    nosm_expert_recover_instructions_prompt_gpt-4-t...      77.0\n",
       "                       expert_recover_pub_instructions_prompt_gpt-4-tu...      80.0\n",
       "haiku                  expert_recover_instructions_prompt_haiku               120.0\n",
       "                       expert_recover_pub_instructions_prompt_haiku           121.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = performance_eval2.drop(columns='File Name') \\\n",
    "    .groupby(['model', 'type'])['lev_dist'] \\\n",
    "    .median() \\\n",
    "    .reset_index() \\\n",
    "    .sort_values('lev_dist') \\\n",
    "    .groupby('model') \\\n",
    "    .head(2) \\\n",
    "    .set_index(['model', 'type']).sort_values('model')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions of the prompt test\n",
    "\n",
    "It appears that the placing the prompt after the text instead of using the system prompt gives the best results. However, the prompts did give significantlty different performance.  I think that perhaps using the `full_context_prompt` and the `expert_recover_publication_prompt` with no system message and the prompt after the text may be the best option. This will require twice as much compute as I was planning to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the test set\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed median difference: 1.7362332392678645\n",
      "P-Value from Bootstrap Test: 0.5289\n"
     ]
    }
   ],
   "source": [
    "#There is no significant difference between nosm and sm so, who knows.\n",
    "\n",
    "test2 = test.groupby('type')['lev_dist'].median().reset_index().copy()\n",
    "\n",
    "test2['system_message'] = ~test2['type'].str.startswith('nosm')\n",
    "\n",
    "test2['new_type'] = test2['type'].str.replace('nosm_', '', regex=True)\n",
    "\n",
    "# Splitting data based on 'system_message'\n",
    "data_true = test2[test2['system_message'] == True]\n",
    "data_false = test2[test2['system_message'] == False]\n",
    "\n",
    "# Merging on 'new_type'\n",
    "merged_data = pd.merge(data_true, data_false, on='new_type', suffixes=('_true', '_false'))\n",
    "\n",
    "# Bootstrap parameters\n",
    "n_bootstrap = 10000\n",
    "differences = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample the merged data with replacement\n",
    "    sample = merged_data.sample(n=len(merged_data), replace=True)\n",
    "    # Compute differences\n",
    "    diff = sample['lev_dist_true'] - sample['lev_dist_false']\n",
    "    # Calculate the median of these differences\n",
    "    differences.append(diff.median())\n",
    "\n",
    "# Calculate observed difference in medians from the original data\n",
    "obs_diff = (merged_data['lev_dist_true'] - merged_data['lev_dist_false']).median()\n",
    "\n",
    "# Estimate the p-value\n",
    "p_value = np.mean(np.abs(differences) >= np.abs(obs_diff))\n",
    "\n",
    "print(\"Observed median difference:\", obs_diff)\n",
    "print(\"P-Value from Bootstrap Test:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
