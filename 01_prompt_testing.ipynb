{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt selection and testing\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, compare_request_configurations, generate_model_configs\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import files_to_df_func, evaluate_ner, calculate_entity_similarity, repeat_prompt_experiment\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "\n",
    "dev_data_folder = 'data/dev_data'\n",
    "dev_transcripts = os.path.join(dev_data_folder, 'dev_data_transcript')\n",
    "dev_raw_ocr_folder =  os.path.join(dev_data_folder,'dev_raw_ocr' )\n",
    "dev_system_message_folder = os.path.join(dev_data_folder,'dev_system_message_variants' )\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv(os.path.join(dev_data_folder,'dev_data_raw.csv'))\n",
    "\n",
    "\n",
    "#for saving data to be used in the analysis\n",
    "if not os.path.exists('data/analysis'):\n",
    "    os.makedirs('data/analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different system prompts\n",
    "\n",
    "This explores a range of system prompt to find the one that appears to work the best, we use gpt4 as the baseline model.\n",
    "\n",
    "Although there is no comparison with all models we do test gpt3.5 gpt4, clause haiku and claude opus, in addition we put the prompt in the system message and the prompt after the text becuase this may affect the quality of the result. When the prompt is after the text the response has \"nosm_\" (no system message) appended to the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a modular set of system messages that can be combined in different ways\n",
    "basic_prompt = \"Please recover the text from the corrupted OCR.\"\n",
    "expertise_prompt = \"You are an expert in post-OCR correction of documents.\"\n",
    "recover_prompt = \"Using the context available from the text please recover the most likely original text from the corrupted OCR.\"\n",
    "publication_context_prompt = \"The text is from an english newspaper in the 1800's.\"\n",
    "text_context_prompt = \"The text may be an advert or article and may be missing the beggining or end.\"\n",
    "additional_instructions_prompt = \"Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\n",
    "\n",
    "#combine all the message parts into a variety of system messages, a tuple is used where 0 is the name of the message and 1 is the message itself\n",
    "#N.B. This is not and exhaustive combination as that would be very expensive and likley not yield significantly better results\n",
    "system_messages_list = [\n",
    "('basic_prompt', basic_prompt),\n",
    "('expert_basic_prompt', expertise_prompt + ' '+ basic_prompt),\n",
    "('expert_recover_prompt', expertise_prompt + ' '+ recover_prompt),\n",
    "('expert_recover_publication_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt),\n",
    "('expert_recover_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_publication_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_instructions_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + additional_instructions_prompt),\n",
    "('full_context_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt+ ' ' + additional_instructions_prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function is used to make the creation of the config dictionaries for the test more compact and increase readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_test_configs(system_messages_list, get_response_func, engine):\n",
    "    message_test_configs = []\n",
    "    for iter_system_message in system_messages_list:\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=iter_system_message[1],\n",
    "                prompt_template=\"{content_html}\",\n",
    "                additional_args={'response_name': iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=\"\",\n",
    "                prompt_template=\"{content_html}\" + f\"\"\"\\n\\n\"\"\" + iter_system_message[1],\n",
    "                additional_args={'response_name': \"nosm_\"+iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "    return message_test_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs and run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt configs\n",
    "gpt3_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, \"gpt-3.5-turbo\")\n",
    "gpt4_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, 'gpt-4-turbo-preview')\n",
    "\n",
    "#claude configs\n",
    "haiku_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-haiku-20240307\")\n",
    "opus_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-opus-20240229\")\n",
    "\n",
    "#run the experiment on all the prompt configs and save to the folder\n",
    "compare_request_configurations(dev_data_df, \n",
    "                               gpt3_prompt_testing_configs + gpt4_prompt_testing_configs + haiku_prompt_testing_configs + opus_prompt_testing_configs,\n",
    "                               folder_path = dev_system_message_folder )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_ocr_scores = evaluate_correction_performance(dev_raw_ocr_folder , dev_transcripts, wer, cer, 'raw_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = dev_system_message_folder\n",
    "\n",
    "performance_eval = evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt'),:]\n",
    "\n",
    "performance_eval['type'] = performance_eval['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "\n",
    "performance_eval['model'] = performance_eval['type'].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>56.55</td>\n",
       "      <td>74.70</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>43.62</td>\n",
       "      <td>-29.53</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.64</td>\n",
       "      <td>75.47</td>\n",
       "      <td>44.57</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.02</td>\n",
       "      <td>48.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.07</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.74</td>\n",
       "      <td>55.14</td>\n",
       "      <td>39.58</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>68.79</td>\n",
       "      <td>77.39</td>\n",
       "      <td>25.49</td>\n",
       "      <td>55.41</td>\n",
       "      <td>25.91</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.19</td>\n",
       "      <td>77.36</td>\n",
       "      <td>44.01</td>\n",
       "      <td>56.22</td>\n",
       "      <td>42.49</td>\n",
       "      <td>53.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.25</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.81</td>\n",
       "      <td>58.38</td>\n",
       "      <td>40.48</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.85</td>\n",
       "      <td>76.02</td>\n",
       "      <td>49.35</td>\n",
       "      <td>58.54</td>\n",
       "      <td>47.96</td>\n",
       "      <td>53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.35</td>\n",
       "      <td>75.86</td>\n",
       "      <td>50.45</td>\n",
       "      <td>58.71</td>\n",
       "      <td>49.13</td>\n",
       "      <td>58.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.73</td>\n",
       "      <td>76.02</td>\n",
       "      <td>47.31</td>\n",
       "      <td>59.73</td>\n",
       "      <td>45.54</td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.79</td>\n",
       "      <td>77.36</td>\n",
       "      <td>42.16</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.97</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>63.66</td>\n",
       "      <td>78.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>63.23</td>\n",
       "      <td>5.51</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>75.92</td>\n",
       "      <td>79.25</td>\n",
       "      <td>59.19</td>\n",
       "      <td>64.39</td>\n",
       "      <td>56.97</td>\n",
       "      <td>61.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.73</td>\n",
       "      <td>77.59</td>\n",
       "      <td>56.30</td>\n",
       "      <td>64.86</td>\n",
       "      <td>54.26</td>\n",
       "      <td>58.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.67</td>\n",
       "      <td>80.46</td>\n",
       "      <td>46.82</td>\n",
       "      <td>68.01</td>\n",
       "      <td>45.19</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.42</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.95</td>\n",
       "      <td>68.78</td>\n",
       "      <td>57.84</td>\n",
       "      <td>66.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.95</td>\n",
       "      <td>80.46</td>\n",
       "      <td>55.57</td>\n",
       "      <td>69.66</td>\n",
       "      <td>53.61</td>\n",
       "      <td>61.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER           CER  \\\n",
       "                                                     mean    50%   mean   \n",
       "type                                                                      \n",
       "nosm_expert_recover_publication_text_prompt_cla...  56.55  74.70 -29.86   \n",
       "nosm_expert_recover_publication_prompt_claude-3...  71.64  75.47  44.57   \n",
       "expert_recover_publication_prompt_claude-3-opus...  71.07  77.36  41.74   \n",
       "full_context_prompt_claude-3-opus-20240229          68.79  77.39  25.49   \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   72.19  77.36  44.01   \n",
       "basic_prompt_claude-3-opus-20240229                 72.25  77.36  41.81   \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   72.85  76.02  49.35   \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  71.35  75.86  50.45   \n",
       "nosm_basic_prompt_claude-3-opus-20240229            70.73  76.02  47.31   \n",
       "expert_recover_publication_text_prompt_claude-3...  70.79  77.36  42.16   \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.66  78.30   4.86   \n",
       "expert_basic_prompt_claude-3-opus-20240229          75.92  79.25  59.19   \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     73.73  77.59  56.30   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  73.67  80.46  46.82   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     73.42  80.46  58.95   \n",
       "nosm_expert_recover_instructions_prompt_claude-...  73.95  80.46  55.57   \n",
       "\n",
       "                                                          lev_dist         \n",
       "                                                      50%     mean    50%  \n",
       "type                                                                       \n",
       "nosm_expert_recover_publication_text_prompt_cla...  43.62   -29.53  45.00  \n",
       "nosm_expert_recover_publication_prompt_claude-3...  49.56    43.02  48.07  \n",
       "expert_recover_publication_prompt_claude-3-opus...  55.14    39.58  52.66  \n",
       "full_context_prompt_claude-3-opus-20240229          55.41    25.91  56.00  \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   56.22    42.49  53.72  \n",
       "basic_prompt_claude-3-opus-20240229                 58.38    40.48  55.60  \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   58.54    47.96  53.88  \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  58.71    49.13  58.31  \n",
       "nosm_basic_prompt_claude-3-opus-20240229            59.73    45.54  49.76  \n",
       "expert_recover_publication_text_prompt_claude-3...  60.00    40.97  55.60  \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.23     5.51  55.60  \n",
       "expert_basic_prompt_claude-3-opus-20240229          64.39    56.97  61.79  \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     64.86    54.26  58.99  \n",
       "expert_recover_instructions_prompt_claude-3-opu...  68.01    45.19  62.87  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     68.78    57.84  66.36  \n",
       "nosm_expert_recover_instructions_prompt_claude-...  69.66    53.61  61.94  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['type'].str.contains('opus')].groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('CER', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>148.67</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>146.67</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158.33</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>149.62</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>160.71</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>168.38</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>192.76</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>153.86</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>208.90</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>158.19</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>163.95</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>154.38</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>153.86</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>233.00</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>307.05</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>229.57</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         WER  \\\n",
       "                                                                        mean   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.23   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.23   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.24   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.23   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.26   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.25   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.26   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.25   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.27   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.24   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.24   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.35   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.34   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.30   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.15   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.16   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.16   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.16   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.21   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.14   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.18   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.18   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.16   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.14   \n",
       "\n",
       "                                                                         CER  \\\n",
       "                                                                        mean   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.13   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.13   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.15   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.15   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.15   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.15   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.14   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.14   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.25   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.23   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.19   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.06   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.06   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.07   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.05   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.05   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.06   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.09   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.06   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.05   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.05   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.05   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.05   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.06   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.06   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.09   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.11   \n",
       "\n",
       "                                                                       lev_dist  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   148.67   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview   146.67   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   158.33   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview   149.62   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview   160.71   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview   168.38   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview   192.76   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview   153.86   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview   208.90   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview   158.19   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview   163.95   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   154.38   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   153.86   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview   233.00   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview   307.05   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview   229.57   \n",
       "\n",
       "                                                                               \n",
       "                                                                          50%  \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   72.0  \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview   75.0  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   76.0  \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview   81.0  \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview   85.0  \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  105.0  \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  110.0  \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  110.0  \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  114.0  \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  114.0  \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  115.0  \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  115.0  \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  118.0  \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  121.0  \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  124.0  \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  129.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions of the prompt test\n",
    "\n",
    "It appears that the placing the prompt after the text instead of using the system prompt gives the best results. However, the prompts did give significantlty different performance.  I think that perhaps using the `full_context_prompt` and the `expert_recover_publication_prompt` with no system message and the prompt after the text may be the best option. This will require twice as much compute as I was planning to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the test set\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
