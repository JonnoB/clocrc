{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt selection and testing\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, compare_request_configurations\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "from helper_functions import files_to_df_func, files_to_df_core_func\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dev_data_folder = 'data/dev_data'\n",
    "dev_transcripts = os.path.join(dev_data_folder, 'dev_data_transcript')\n",
    "dev_raw_ocr_folder =  os.path.join(dev_data_folder,'dev_raw_ocr' )\n",
    "dev_system_message_folder = os.path.join(dev_data_folder,'dev_system_message_variants' )\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv(os.path.join(dev_data_folder,'dev_data_raw.csv'))\n",
    "\n",
    "\n",
    "#for saving data to be used in the analysis\n",
    "if not os.path.exists('data/analysis'):\n",
    "    os.makedirs('data/analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different system prompts\n",
    "\n",
    "This explores a range of system prompt to find the one that appears to work the best, we use gpt4 as the baseline model.\n",
    "\n",
    "Although there is no comparison with all models we do test gpt3.5 gpt4, clause haiku and claude opus, in addition we put the prompt in the system message and the prompt after the text becuase this may affect the quality of the result. When the prompt is after the text the response has \"nosm_\" (no system message) appended to the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a modular set of system messages that can be combined in different ways\n",
    "basic_prompt = \"Please recover the text from the corrupted OCR.\"\n",
    "expertise_prompt = \"You are an expert in post-OCR correction of documents.\"\n",
    "recover_prompt = \"Using the context available from the text please recover the most likely original text from the corrupted OCR.\"\n",
    "publication_context_prompt = \"The text is from an english newspaper in the 1800's.\"\n",
    "text_context_prompt = \"The text may be an advert or article and may be missing the beggining or end.\"\n",
    "additional_instructions_prompt = \"Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\n",
    "\n",
    "#combine all the message parts into a variety of system messages, a tuple is used where 0 is the name of the message and 1 is the message itself\n",
    "#N.B. This is not and exhaustive combination as that would be very expensive and likley not yield significantly better results\n",
    "system_messages_list = [\n",
    "('basic_prompt', basic_prompt),\n",
    "('expert_basic_prompt', expertise_prompt + ' '+ basic_prompt),\n",
    "('expert_recover_prompt', expertise_prompt + ' '+ recover_prompt),\n",
    "('expert_recover_publication_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt),\n",
    "('expert_recover_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_publication_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_instructions_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + additional_instructions_prompt),\n",
    "('full_context_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt+ ' ' + additional_instructions_prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function is used to make the creation of the config dictionaries for the test more compact and increase readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_test_configs(system_messages_list, get_response_func, engine):\n",
    "    message_test_configs = []\n",
    "    for iter_system_message in system_messages_list:\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=iter_system_message[1],\n",
    "                prompt_template=\"{content_html}\",\n",
    "                additional_args={'response_name': iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=\"\",\n",
    "                prompt_template=\"{content_html}\" + f\"\"\"\\n\\n\"\"\" + iter_system_message[1],\n",
    "                additional_args={'response_name': \"nosm_\"+iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "    return message_test_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs and run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt configs\n",
    "gpt3_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, \"gpt-3.5-turbo\")\n",
    "gpt4_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, 'gpt-4-turbo-preview')\n",
    "\n",
    "#claude configs\n",
    "haiku_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-haiku-20240307\")\n",
    "opus_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-opus-20240229\")\n",
    "\n",
    "#run the experiment on all the prompt configs and save to the folder\n",
    "compare_request_configurations(dev_data_df, \n",
    "                               gpt3_prompt_testing_configs + gpt4_prompt_testing_configs + haiku_prompt_testing_configs + opus_prompt_testing_configs,\n",
    "                               folder_path = dev_system_message_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_test_df = []\n",
    "for folder in os.listdir(dev_system_message_folder):\n",
    "    df = files_to_df_core_func(dev_system_message_folder)\n",
    "    df['folder'] = folder\n",
    "    prompt_test_df.append(df)\n",
    "\n",
    "prompt_test_df = pd.concat(prompt_test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_ocr_scores = evaluate_correction_performance(dev_raw_ocr_folder , dev_transcripts, wer, cer, 'raw_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = dev_system_message_folder\n",
    "\n",
    "performance_eval = evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt'),:]\n",
    "\n",
    "performance_eval['type'] = performance_eval['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "\n",
    "performance_eval['model'] = performance_eval['type'].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_haiku</th>\n",
       "      <td>-3.36</td>\n",
       "      <td>13.64</td>\n",
       "      <td>-296.74</td>\n",
       "      <td>-197.56</td>\n",
       "      <td>-282.00</td>\n",
       "      <td>-177.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_haiku</th>\n",
       "      <td>4.55</td>\n",
       "      <td>18.18</td>\n",
       "      <td>-294.91</td>\n",
       "      <td>-152.94</td>\n",
       "      <td>-279.84</td>\n",
       "      <td>-144.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_haiku</th>\n",
       "      <td>17.73</td>\n",
       "      <td>35.45</td>\n",
       "      <td>-209.70</td>\n",
       "      <td>-115.22</td>\n",
       "      <td>-198.48</td>\n",
       "      <td>-110.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_haiku</th>\n",
       "      <td>1.70</td>\n",
       "      <td>11.65</td>\n",
       "      <td>-297.54</td>\n",
       "      <td>-107.24</td>\n",
       "      <td>-280.89</td>\n",
       "      <td>-102.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_haiku</th>\n",
       "      <td>39.84</td>\n",
       "      <td>48.11</td>\n",
       "      <td>-90.64</td>\n",
       "      <td>-39.82</td>\n",
       "      <td>-85.44</td>\n",
       "      <td>-36.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>73.21</td>\n",
       "      <td>77.19</td>\n",
       "      <td>54.38</td>\n",
       "      <td>63.78</td>\n",
       "      <td>52.09</td>\n",
       "      <td>62.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.67</td>\n",
       "      <td>80.46</td>\n",
       "      <td>46.82</td>\n",
       "      <td>68.01</td>\n",
       "      <td>45.19</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>73.61</td>\n",
       "      <td>77.59</td>\n",
       "      <td>55.55</td>\n",
       "      <td>62.80</td>\n",
       "      <td>53.41</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>72.03</td>\n",
       "      <td>75.86</td>\n",
       "      <td>49.27</td>\n",
       "      <td>65.55</td>\n",
       "      <td>47.03</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.42</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.95</td>\n",
       "      <td>68.78</td>\n",
       "      <td>57.84</td>\n",
       "      <td>66.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER            CER  \\\n",
       "                                                     mean    50%    mean   \n",
       "type                                                                       \n",
       "expert_recover_text_prompt_haiku                    -3.36  13.64 -296.74   \n",
       "nosm_expert_recover_publication_text_prompt_haiku    4.55  18.18 -294.91   \n",
       "expert_recover_publication_text_prompt_haiku        17.73  35.45 -209.70   \n",
       "nosm_expert_recover_text_prompt_haiku                1.70  11.65 -297.54   \n",
       "expert_recover_prompt_haiku                         39.84  48.11  -90.64   \n",
       "...                                                   ...    ...     ...   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview        73.21  77.19   54.38   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  73.67  80.46   46.82   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview        73.61  77.59   55.55   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview      72.03  75.86   49.27   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     73.42  80.46   58.95   \n",
       "\n",
       "                                                           lev_dist          \n",
       "                                                       50%     mean     50%  \n",
       "type                                                                         \n",
       "expert_recover_text_prompt_haiku                   -197.56  -282.00 -177.78  \n",
       "nosm_expert_recover_publication_text_prompt_haiku  -152.94  -279.84 -144.31  \n",
       "expert_recover_publication_text_prompt_haiku       -115.22  -198.48 -110.20  \n",
       "nosm_expert_recover_text_prompt_haiku              -107.24  -280.89 -102.16  \n",
       "expert_recover_prompt_haiku                         -39.82   -85.44  -36.21  \n",
       "...                                                    ...      ...     ...  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview         63.78    52.09   62.23  \n",
       "expert_recover_instructions_prompt_claude-3-opu...   68.01    45.19   62.87  \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview         62.80    53.41   63.64  \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview       65.55    47.03   63.79  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229      68.78    57.84   66.36  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>56.55</td>\n",
       "      <td>74.70</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>43.62</td>\n",
       "      <td>-29.53</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.64</td>\n",
       "      <td>75.47</td>\n",
       "      <td>44.57</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.02</td>\n",
       "      <td>48.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.73</td>\n",
       "      <td>76.02</td>\n",
       "      <td>47.31</td>\n",
       "      <td>59.73</td>\n",
       "      <td>45.54</td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.07</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.74</td>\n",
       "      <td>55.14</td>\n",
       "      <td>39.58</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.19</td>\n",
       "      <td>77.36</td>\n",
       "      <td>44.01</td>\n",
       "      <td>56.22</td>\n",
       "      <td>42.49</td>\n",
       "      <td>53.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.85</td>\n",
       "      <td>76.02</td>\n",
       "      <td>49.35</td>\n",
       "      <td>58.54</td>\n",
       "      <td>47.96</td>\n",
       "      <td>53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.25</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.81</td>\n",
       "      <td>58.38</td>\n",
       "      <td>40.48</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>63.66</td>\n",
       "      <td>78.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>63.23</td>\n",
       "      <td>5.51</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.79</td>\n",
       "      <td>77.36</td>\n",
       "      <td>42.16</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.97</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>68.79</td>\n",
       "      <td>77.39</td>\n",
       "      <td>25.49</td>\n",
       "      <td>55.41</td>\n",
       "      <td>25.91</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.35</td>\n",
       "      <td>75.86</td>\n",
       "      <td>50.45</td>\n",
       "      <td>58.71</td>\n",
       "      <td>49.13</td>\n",
       "      <td>58.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.73</td>\n",
       "      <td>77.59</td>\n",
       "      <td>56.30</td>\n",
       "      <td>64.86</td>\n",
       "      <td>54.26</td>\n",
       "      <td>58.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>75.92</td>\n",
       "      <td>79.25</td>\n",
       "      <td>59.19</td>\n",
       "      <td>64.39</td>\n",
       "      <td>56.97</td>\n",
       "      <td>61.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.95</td>\n",
       "      <td>80.46</td>\n",
       "      <td>55.57</td>\n",
       "      <td>69.66</td>\n",
       "      <td>53.61</td>\n",
       "      <td>61.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.67</td>\n",
       "      <td>80.46</td>\n",
       "      <td>46.82</td>\n",
       "      <td>68.01</td>\n",
       "      <td>45.19</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.42</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.95</td>\n",
       "      <td>68.78</td>\n",
       "      <td>57.84</td>\n",
       "      <td>66.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER           CER  \\\n",
       "                                                     mean    50%   mean   \n",
       "type                                                                      \n",
       "nosm_expert_recover_publication_text_prompt_cla...  56.55  74.70 -29.86   \n",
       "nosm_expert_recover_publication_prompt_claude-3...  71.64  75.47  44.57   \n",
       "nosm_basic_prompt_claude-3-opus-20240229            70.73  76.02  47.31   \n",
       "expert_recover_publication_prompt_claude-3-opus...  71.07  77.36  41.74   \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   72.19  77.36  44.01   \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   72.85  76.02  49.35   \n",
       "basic_prompt_claude-3-opus-20240229                 72.25  77.36  41.81   \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.66  78.30   4.86   \n",
       "expert_recover_publication_text_prompt_claude-3...  70.79  77.36  42.16   \n",
       "full_context_prompt_claude-3-opus-20240229          68.79  77.39  25.49   \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  71.35  75.86  50.45   \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     73.73  77.59  56.30   \n",
       "expert_basic_prompt_claude-3-opus-20240229          75.92  79.25  59.19   \n",
       "nosm_expert_recover_instructions_prompt_claude-...  73.95  80.46  55.57   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  73.67  80.46  46.82   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     73.42  80.46  58.95   \n",
       "\n",
       "                                                          lev_dist         \n",
       "                                                      50%     mean    50%  \n",
       "type                                                                       \n",
       "nosm_expert_recover_publication_text_prompt_cla...  43.62   -29.53  45.00  \n",
       "nosm_expert_recover_publication_prompt_claude-3...  49.56    43.02  48.07  \n",
       "nosm_basic_prompt_claude-3-opus-20240229            59.73    45.54  49.76  \n",
       "expert_recover_publication_prompt_claude-3-opus...  55.14    39.58  52.66  \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   56.22    42.49  53.72  \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   58.54    47.96  53.88  \n",
       "basic_prompt_claude-3-opus-20240229                 58.38    40.48  55.60  \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.23     5.51  55.60  \n",
       "expert_recover_publication_text_prompt_claude-3...  60.00    40.97  55.60  \n",
       "full_context_prompt_claude-3-opus-20240229          55.41    25.91  56.00  \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  58.71    49.13  58.31  \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     64.86    54.26  58.99  \n",
       "expert_basic_prompt_claude-3-opus-20240229          64.39    56.97  61.79  \n",
       "nosm_expert_recover_instructions_prompt_claude-...  69.66    53.61  61.94  \n",
       "expert_recover_instructions_prompt_claude-3-opu...  68.01    45.19  62.87  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     68.78    57.84  66.36  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['type'].str.contains('opus')].groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>148.67</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>146.67</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>173.90</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158.33</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>163.38</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>433.38</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>577.19</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>626.38</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>784.00</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.54</td>\n",
       "      <td>602.14</td>\n",
       "      <td>566.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            WER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.23   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.23   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.24   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.24   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.25   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.57   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.71   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.81   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.83   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.81   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.15   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.12   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.16   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.11   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.51   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.51   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.73   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.90   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.68   \n",
       "\n",
       "                                                                            CER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.13   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.14   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.14   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.15   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.44   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.58   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.65   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.68   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.66   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.06   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.06   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.05   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.07   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.04   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.42   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.41   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.65   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.70   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.54   \n",
       "\n",
       "                                                                          lev_dist  \\\n",
       "                                                                              mean   \n",
       "type                                               model                             \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      148.67   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      146.67   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   173.90   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      158.33   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229   163.38   \n",
       "...                                                                            ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                    433.38   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                    577.19   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                    626.38   \n",
       "expert_recover_text_prompt_haiku                   haiku                    784.00   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                    602.14   \n",
       "\n",
       "                                                                                  \n",
       "                                                                             50%  \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      72.0  \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      75.0  \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   75.0  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      76.0  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229   76.0  \n",
       "...                                                                          ...  \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   395.0  \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   525.0  \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   545.0  \n",
       "expert_recover_text_prompt_haiku                   haiku                   545.0  \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   566.0  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "#performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">claude-3-opus-20240229</th>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>expert_recover_publication_text_prompt_gpt-3.5-turbo</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_gpt-3.5-turbo</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpt-4-turbo-preview</th>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">haiku</th>\n",
       "      <th>expert_recover_instructions_prompt_haiku</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_haiku</th>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           lev_dist\n",
       "model                  type                                                        \n",
       "claude-3-opus-20240229 expert_recover_instructions_prompt_claude-3-opu...      75.0\n",
       "                       nosm_full_context_prompt_claude-3-opus-20240229         76.0\n",
       "gpt-3.5-turbo          expert_recover_publication_text_prompt_gpt-3.5-...     111.0\n",
       "                       expert_recover_publication_prompt_gpt-3.5-turbo        111.0\n",
       "gpt-4-turbo-preview    full_context_prompt_gpt-4-turbo-preview                 72.0\n",
       "                       nosm_expert_recover_instructions_prompt_gpt-4-t...      75.0\n",
       "haiku                  expert_recover_instructions_prompt_haiku               110.0\n",
       "                       nosm_expert_recover_instructions_prompt_haiku          122.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = performance_eval2.drop(columns='File Name') \\\n",
    "    .groupby(['model', 'type'])['lev_dist'] \\\n",
    "    .median() \\\n",
    "    .reset_index() \\\n",
    "    .sort_values('lev_dist') \\\n",
    "    .groupby('model') \\\n",
    "    .head(2) \\\n",
    "    .set_index(['model', 'type']).sort_values('model')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions of the prompt test\n",
    "\n",
    "It appears that the placing the prompt after the text instead of using the system prompt gives the best results. However, the prompts did give significantlty different performance.  I think that perhaps using the `full_context_prompt` and the `expert_recover_publication_prompt` with no system message and the prompt after the text may be the best option. This will require twice as much compute as I was planning to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the test set\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
