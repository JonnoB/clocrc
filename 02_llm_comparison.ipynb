{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt selection and testing\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, compare_request_configurations, generate_model_configs\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import files_to_df_func, evaluate_ner, calculate_entity_similarity, repeat_prompt_experiment\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "\n",
    "dev_data_folder = 'data/dev_data'\n",
    "dev_transcripts = os.path.join(dev_data_folder, 'dev_data_transcript')\n",
    "dev_raw_ocr_folder =  os.path.join(dev_data_folder,'dev_raw_ocr' )\n",
    "dev_system_message_folder = os.path.join(dev_data_folder,'dev_system_message_variants' )\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv(os.path.join(dev_data_folder,'dev_data_raw.csv'))\n",
    "\n",
    "\n",
    "#for saving data to be used in the analysis\n",
    "if not os.path.exists('data/analysis'):\n",
    "    os.makedirs('data/analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the test set\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create API configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the prompt/system message using the best performing from the previous section\n",
    "\n",
    "full_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. The text is from an english newspaper in the 1800's. The text may be an advert or article and may be missing the beggining or end. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "instruct_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "boros_basic  = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" +\"Correct the text\"\n",
    "\n",
    "boros_complex  =\"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"Please assist with reviewing and correcting errors in texts produced by automatic transcription (OCR) of historical documents.\n",
    "Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. \n",
    "Do not write anything else than the corrected text.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_alt_endpoint = {'alt_endpoint':{'base_url':'https://api.groq.com/openai/v1',\n",
    "                     'api_key':os.getenv(\"GROQ_API_KEY\")}}\n",
    "\n",
    "basic_model_configs = pd.DataFrame({\n",
    "    'get_response_func': [get_response_openai, get_response_openai, get_response_anthropic, get_response_anthropic, \n",
    "                          get_response_openai, get_response_openai, get_response_openai], \n",
    "    'engine': ['gpt-3.5-turbo', 'gpt-4-turbo-preview', \"claude-3-haiku-20240307\", \"claude-3-opus-20240229\", \n",
    "               'mixtral-8x7b-32768', 'llama2-70b-4096', 'gemma-7b-it'],\n",
    "    'rate_limit':[160e3, 80e3, 100e3, 40e3, 18e3, 30e3, 30e3],\n",
    "    'additional_args': [\n",
    "        {}, {}, {}, {}, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint\n",
    "    ]\n",
    "})\n",
    "\n",
    "full_model_configs = generate_model_configs(basic_model_configs, full_prompt, 'full')\n",
    "instruct_model_configs = generate_model_configs(basic_model_configs, instruct_prompt, 'instruct')\n",
    "\n",
    "#I think on reflection I only need to compare boros complex on gpt-4 as this was the best performer in their paper\n",
    "boros_configs = [\n",
    "    (get_response_openai, 'gpt-4-turbo-preview', boros_complex, \"boros_complex_\"),\n",
    "   # (get_response_openai, 'gpt-4-turbo-preview', boros_basic, \"boros_basic_\"),\n",
    "  #  (get_response_anthropic, \"claude-3-opus-20240229\", boros_complex, \"boros_complex_\")\n",
    "]\n",
    "\n",
    "boros_list = [\n",
    "    create_config_dict_func(\n",
    "        get_response_func=config[0],\n",
    "        rate_limiter=RateLimiter(80e3),\n",
    "        engine=config[1],\n",
    "        system_message_template=\"\",\n",
    "        prompt_template=config[2],\n",
    "        additional_args={\"response_name\": config[3]}\n",
    "    )\n",
    "    for config in boros_configs\n",
    "]\n",
    "\n",
    "model_configs = full_model_configs + instruct_model_configs + boros_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform all API calls\n",
    "\n",
    "The below section is what actually calls the API, the code points to the folders where the raw OCR is and provides a path to where the corrected text should be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = 'data/transcription_returned_ocr/corrected_folder'\n",
    "#\n",
    "# This naming business needs to be cleaned up so the actual article ID is used. until then just have the following mess\n",
    "#\n",
    "# \n",
    "\n",
    "test_data_new = pd.read_csv(os.path.join(dev_data_folder,'transcription_raw_ocr.csv'))\n",
    "test_data_new = test_data_new.loc[test_data_new ['file_name'].isin(files_to_df_func(dev_raw_ocr_folder )['file_name'])]\n",
    "\n",
    "#used on the original devset\n",
    "#compare_request_configurations(dev_data_df, model_configs, folder_path='./data/dev_corrected_base')\n",
    "#This goes through the list of articles that have been transcribed, checks to see if there is a corrected version and if not generates it\n",
    "compare_request_configurations(test_data_new, model_configs, folder_path=corrected_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sydney Morning Herald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronicalling America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the prompts across all models\n",
    "\n",
    "On the smaller models, Full is worse than instruct on the larger models the reverse. Maybe this is related to ability to 'focus' or hold isntructions in memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = dev_system_message_folder \n",
    "\n",
    "performance_eval =  evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt') &\n",
    "                     (performance_eval['type']!='gpt3_boros_blank_gpt-3.5-turbo'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_claude-3-haiku-20240307</th>\n",
       "      <td>-3.36</td>\n",
       "      <td>13.64</td>\n",
       "      <td>-296.74</td>\n",
       "      <td>-197.56</td>\n",
       "      <td>-282.00</td>\n",
       "      <td>-177.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_claude-3-haiku-20240307</th>\n",
       "      <td>4.55</td>\n",
       "      <td>18.18</td>\n",
       "      <td>-294.91</td>\n",
       "      <td>-152.94</td>\n",
       "      <td>-279.84</td>\n",
       "      <td>-144.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_claude-3-haiku-20240307</th>\n",
       "      <td>17.73</td>\n",
       "      <td>35.45</td>\n",
       "      <td>-209.70</td>\n",
       "      <td>-115.22</td>\n",
       "      <td>-198.48</td>\n",
       "      <td>-110.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_claude-3-haiku-20240307</th>\n",
       "      <td>1.70</td>\n",
       "      <td>11.65</td>\n",
       "      <td>-297.54</td>\n",
       "      <td>-107.24</td>\n",
       "      <td>-280.89</td>\n",
       "      <td>-102.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_claude-3-haiku-20240307</th>\n",
       "      <td>39.84</td>\n",
       "      <td>48.11</td>\n",
       "      <td>-90.64</td>\n",
       "      <td>-39.82</td>\n",
       "      <td>-85.44</td>\n",
       "      <td>-36.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>73.21</td>\n",
       "      <td>77.19</td>\n",
       "      <td>54.38</td>\n",
       "      <td>63.78</td>\n",
       "      <td>52.09</td>\n",
       "      <td>62.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.67</td>\n",
       "      <td>80.46</td>\n",
       "      <td>46.82</td>\n",
       "      <td>68.01</td>\n",
       "      <td>45.19</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>73.61</td>\n",
       "      <td>77.59</td>\n",
       "      <td>55.55</td>\n",
       "      <td>62.80</td>\n",
       "      <td>53.41</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <td>72.03</td>\n",
       "      <td>75.86</td>\n",
       "      <td>49.27</td>\n",
       "      <td>65.55</td>\n",
       "      <td>47.03</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.42</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.95</td>\n",
       "      <td>68.78</td>\n",
       "      <td>57.84</td>\n",
       "      <td>66.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER            CER  \\\n",
       "                                                     mean    50%    mean   \n",
       "type                                                                       \n",
       "expert_recover_text_prompt_claude-3-haiku-20240307  -3.36  13.64 -296.74   \n",
       "nosm_expert_recover_publication_text_prompt_cla...   4.55  18.18 -294.91   \n",
       "expert_recover_publication_text_prompt_claude-3...  17.73  35.45 -209.70   \n",
       "nosm_expert_recover_text_prompt_claude-3-haiku-...   1.70  11.65 -297.54   \n",
       "expert_recover_prompt_claude-3-haiku-20240307       39.84  48.11  -90.64   \n",
       "...                                                   ...    ...     ...   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview        73.21  77.19   54.38   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  73.67  80.46   46.82   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview        73.61  77.59   55.55   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview      72.03  75.86   49.27   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     73.42  80.46   58.95   \n",
       "\n",
       "                                                           lev_dist          \n",
       "                                                       50%     mean     50%  \n",
       "type                                                                         \n",
       "expert_recover_text_prompt_claude-3-haiku-20240307 -197.56  -282.00 -177.78  \n",
       "nosm_expert_recover_publication_text_prompt_cla... -152.94  -279.84 -144.31  \n",
       "expert_recover_publication_text_prompt_claude-3... -115.22  -198.48 -110.20  \n",
       "nosm_expert_recover_text_prompt_claude-3-haiku-... -107.24  -280.89 -102.16  \n",
       "expert_recover_prompt_claude-3-haiku-20240307       -39.82   -85.44  -36.21  \n",
       "...                                                    ...      ...     ...  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview         63.78    52.09   62.23  \n",
       "expert_recover_instructions_prompt_claude-3-opu...   68.01    45.19   62.87  \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview         62.80    53.41   63.64  \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview       65.55    47.03   63.79  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229      68.78    57.84   66.36  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_reduction = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)\n",
    "\n",
    "\n",
    "error_reduction.to_csv('data/analysis/error_reduction.csv', index=False)\n",
    "\n",
    "\n",
    "error_reduction.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>148.67</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>146.67</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>173.90</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158.33</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>163.38</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>433.38</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>577.19</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>626.38</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>784.00</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.54</td>\n",
       "      <td>602.14</td>\n",
       "      <td>566.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            WER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.23   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.23   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.24   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.24   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.25   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.57   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.71   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.81   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.83   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.81   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.15   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.12   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.16   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.11   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.51   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.51   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.73   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.90   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.68   \n",
       "\n",
       "                                                                            CER  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.13   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.14   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.14   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.15   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.44   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.58   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.65   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.68   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.66   \n",
       "\n",
       "                                                                                 \\\n",
       "                                                                            50%   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview     0.06   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview     0.06   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229  0.05   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview     0.07   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229  0.04   \n",
       "...                                                                         ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   0.42   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   0.41   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   0.65   \n",
       "expert_recover_text_prompt_haiku                   haiku                   0.70   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   0.54   \n",
       "\n",
       "                                                                          lev_dist  \\\n",
       "                                                                              mean   \n",
       "type                                               model                             \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      148.67   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      146.67   \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   173.90   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      158.33   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229   163.38   \n",
       "...                                                                            ...   \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                    433.38   \n",
       "expert_recover_publication_text_prompt_haiku       haiku                    577.19   \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                    626.38   \n",
       "expert_recover_text_prompt_haiku                   haiku                    784.00   \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                    602.14   \n",
       "\n",
       "                                                                                  \n",
       "                                                                             50%  \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview      72.0  \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview      75.0  \n",
       "expert_recover_instructions_prompt_claude-3-opu... claude-3-opus-20240229   75.0  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview      76.0  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229    claude-3-opus-20240229   76.0  \n",
       "...                                                                          ...  \n",
       "nosm_expert_recover_publication_prompt_haiku       haiku                   395.0  \n",
       "expert_recover_publication_text_prompt_haiku       haiku                   525.0  \n",
       "nosm_expert_recover_text_prompt_haiku              haiku                   545.0  \n",
       "expert_recover_text_prompt_haiku                   haiku                   545.0  \n",
       "nosm_expert_recover_publication_text_prompt_haiku  haiku                   566.0  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "\n",
    "#The below line allows you to look at an individual model\n",
    "#performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on the test set\n",
    "confusing but you know what I mean, This is jsut to make sure it all works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_files = 'data/transcription_returned_ocr/transcription_files'\n",
    "\n",
    "corrected_folder = 'data/transcription_returned_ocr/corrected_folder'\n",
    "\n",
    "raw_folder = \"/home/jonno/redigitalize/data/transcription_raw_ocr\"\n",
    "\n",
    "performance_eval =  evaluate_correction_performance_folders(corrected_folder, transcribed_files, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt') &\n",
    "                     (performance_eval['type']!='gpt3_boros_blank_gpt-3.5-turbo'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>lev_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.427249</td>\n",
       "      <td>0.320615</td>\n",
       "      <td>674.836420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.404056</td>\n",
       "      <td>1.181777</td>\n",
       "      <td>1563.578346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.047231</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>55.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.160026</td>\n",
       "      <td>0.080230</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.224831</td>\n",
       "      <td>446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.497006</td>\n",
       "      <td>13.418564</td>\n",
       "      <td>15369.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              WER         CER      lev_dist\n",
       "count  324.000000  324.000000    324.000000\n",
       "mean     0.427249    0.320615    674.836420\n",
       "std      1.404056    1.181777   1563.578346\n",
       "min      0.000000    0.000000      1.000000\n",
       "25%      0.047231    0.017892     55.750000\n",
       "50%      0.160026    0.080230    130.000000\n",
       "75%      0.383333    0.224831    446.000000\n",
       "max     17.497006   13.418564  15369.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <td>10.12</td>\n",
       "      <td>27.19</td>\n",
       "      <td>-253.41</td>\n",
       "      <td>-60.56</td>\n",
       "      <td>-249.00</td>\n",
       "      <td>-53.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <td>24.95</td>\n",
       "      <td>39.52</td>\n",
       "      <td>-172.24</td>\n",
       "      <td>-37.54</td>\n",
       "      <td>-168.29</td>\n",
       "      <td>-35.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <td>36.60</td>\n",
       "      <td>43.54</td>\n",
       "      <td>-133.47</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-134.53</td>\n",
       "      <td>-33.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <td>44.84</td>\n",
       "      <td>55.42</td>\n",
       "      <td>-81.32</td>\n",
       "      <td>-27.66</td>\n",
       "      <td>-79.69</td>\n",
       "      <td>-28.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-haiku-20240307</th>\n",
       "      <td>21.36</td>\n",
       "      <td>57.17</td>\n",
       "      <td>-295.09</td>\n",
       "      <td>-4.68</td>\n",
       "      <td>-285.72</td>\n",
       "      <td>-2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <td>-15.26</td>\n",
       "      <td>42.98</td>\n",
       "      <td>-374.12</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-356.15</td>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-haiku-20240307</th>\n",
       "      <td>40.83</td>\n",
       "      <td>57.99</td>\n",
       "      <td>-189.58</td>\n",
       "      <td>9.43</td>\n",
       "      <td>-183.53</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <td>-161.34</td>\n",
       "      <td>58.97</td>\n",
       "      <td>-991.54</td>\n",
       "      <td>15.29</td>\n",
       "      <td>-909.02</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <td>59.10</td>\n",
       "      <td>70.00</td>\n",
       "      <td>-45.12</td>\n",
       "      <td>39.74</td>\n",
       "      <td>-42.64</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <td>56.68</td>\n",
       "      <td>75.36</td>\n",
       "      <td>-17.02</td>\n",
       "      <td>48.57</td>\n",
       "      <td>-14.90</td>\n",
       "      <td>47.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__claude-3-opus-20240229</th>\n",
       "      <td>25.70</td>\n",
       "      <td>81.12</td>\n",
       "      <td>-192.53</td>\n",
       "      <td>58.70</td>\n",
       "      <td>-173.41</td>\n",
       "      <td>58.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <td>77.58</td>\n",
       "      <td>80.38</td>\n",
       "      <td>59.46</td>\n",
       "      <td>62.84</td>\n",
       "      <td>57.26</td>\n",
       "      <td>61.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_basic__gpt-4-turbo-preview</th>\n",
       "      <td>76.37</td>\n",
       "      <td>77.21</td>\n",
       "      <td>55.96</td>\n",
       "      <td>62.65</td>\n",
       "      <td>54.33</td>\n",
       "      <td>62.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <td>78.17</td>\n",
       "      <td>79.38</td>\n",
       "      <td>61.62</td>\n",
       "      <td>66.50</td>\n",
       "      <td>59.28</td>\n",
       "      <td>63.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__gpt-4-turbo-preview</th>\n",
       "      <td>79.80</td>\n",
       "      <td>84.22</td>\n",
       "      <td>66.96</td>\n",
       "      <td>70.37</td>\n",
       "      <td>64.79</td>\n",
       "      <td>67.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <td>-4.45</td>\n",
       "      <td>82.24</td>\n",
       "      <td>-375.41</td>\n",
       "      <td>78.35</td>\n",
       "      <td>-335.13</td>\n",
       "      <td>75.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_temp_claude-3-opus-20240229</th>\n",
       "      <td>22.89</td>\n",
       "      <td>82.24</td>\n",
       "      <td>-231.82</td>\n",
       "      <td>78.64</td>\n",
       "      <td>-205.53</td>\n",
       "      <td>76.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <td>-136.72</td>\n",
       "      <td>79.25</td>\n",
       "      <td>-1519.07</td>\n",
       "      <td>78.89</td>\n",
       "      <td>-1449.43</td>\n",
       "      <td>76.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          WER             CER        lev_dist  \\\n",
       "                                         mean    50%     mean    50%     mean   \n",
       "type                                                                            \n",
       "full__gemma-7b-it                       10.12  27.19  -253.41 -60.56  -249.00   \n",
       "instruct__gemma-7b-it                   24.95  39.52  -172.24 -37.54  -168.29   \n",
       "full__mixtral-8x7b-32768                36.60  43.54  -133.47 -37.87  -134.53   \n",
       "instruct__mixtral-8x7b-32768            44.84  55.42   -81.32 -27.66   -79.69   \n",
       "full__claude-3-haiku-20240307           21.36  57.17  -295.09  -4.68  -285.72   \n",
       "instruct__llama2-70b-4096              -15.26  42.98  -374.12  -0.88  -356.15   \n",
       "instruct__claude-3-haiku-20240307       40.83  57.99  -189.58   9.43  -183.53   \n",
       "full__llama2-70b-4096                 -161.34  58.97  -991.54  15.29  -909.02   \n",
       "full__gpt-3.5-turbo                     59.10  70.00   -45.12  39.74   -42.64   \n",
       "instruct__gpt-3.5-turbo                 56.68  75.36   -17.02  48.57   -14.90   \n",
       "boros_complex__claude-3-opus-20240229   25.70  81.12  -192.53  58.70  -173.41   \n",
       "full__gpt-4-turbo-preview               77.58  80.38    59.46  62.84    57.26   \n",
       "boros_basic__gpt-4-turbo-preview        76.37  77.21    55.96  62.65    54.33   \n",
       "instruct__gpt-4-turbo-preview           78.17  79.38    61.62  66.50    59.28   \n",
       "boros_complex__gpt-4-turbo-preview      79.80  84.22    66.96  70.37    64.79   \n",
       "full__claude-3-opus-20240229            -4.45  82.24  -375.41  78.35  -335.13   \n",
       "claude_temp_claude-3-opus-20240229      22.89  82.24  -231.82  78.64  -205.53   \n",
       "instruct__claude-3-opus-20240229      -136.72  79.25 -1519.07  78.89 -1449.43   \n",
       "\n",
       "                                              \n",
       "                                         50%  \n",
       "type                                          \n",
       "full__gemma-7b-it                     -53.34  \n",
       "instruct__gemma-7b-it                 -35.61  \n",
       "full__mixtral-8x7b-32768              -33.88  \n",
       "instruct__mixtral-8x7b-32768          -28.71  \n",
       "full__claude-3-haiku-20240307          -2.99  \n",
       "instruct__llama2-70b-4096              -0.36  \n",
       "instruct__claude-3-haiku-20240307       9.42  \n",
       "full__llama2-70b-4096                  14.65  \n",
       "full__gpt-3.5-turbo                    39.18  \n",
       "instruct__gpt-3.5-turbo                47.85  \n",
       "boros_complex__claude-3-opus-20240229  58.29  \n",
       "full__gpt-4-turbo-preview              61.85  \n",
       "boros_basic__gpt-4-turbo-preview       62.33  \n",
       "instruct__gpt-4-turbo-preview          63.97  \n",
       "boros_complex__gpt-4-turbo-preview     67.48  \n",
       "full__claude-3-opus-20240229           75.89  \n",
       "claude_temp_claude-3-opus-20240229     76.17  \n",
       "instruct__claude-3-opus-20240229       76.44  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dev_ocr_scores = evaluate_correction_performance(raw_folder, transcribed_files, wer, cer, 'raw_ocr')\n",
    "\n",
    "error_reduction_df = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)\n",
    "\n",
    "error_reduction_df.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
