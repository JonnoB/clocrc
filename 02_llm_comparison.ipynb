{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, compare_request_configurations, generate_model_configs\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import files_to_df_func, files_to_df_core_func\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "\n",
    "dev_data_folder = 'data/dev_data'\n",
    "dev_transcripts = os.path.join(dev_data_folder, 'dev_data_transcript')\n",
    "dev_raw_ocr_folder =  os.path.join(dev_data_folder,'dev_raw_ocr' )\n",
    "dev_system_message_folder = os.path.join(dev_data_folder,'dev_system_message_variants' )\n",
    "\n",
    "\n",
    "#NCSE\n",
    "\n",
    "ncse_folder = 'data/transcription_returned_ocr'\n",
    "ncse_articles_raw = os.path.join(ncse_folder, 'transcription_raw_ocr')\n",
    "ncse_articles_transcribed = os.path.join(ncse_folder, 'transcription_files') \n",
    "ncse_articles_results = os.path.join(ncse_folder, 'corrected_folder')\n",
    "\n",
    "#Overproof\n",
    "overproof_folder = 'data/overproof'\n",
    "\n",
    "smh_folder =  os.path.join(overproof_folder, 'SMH')\n",
    "smh_articles_raw = os.path.join(smh_folder, 'article_level', 'raw')\n",
    "smh_articles_transcribed = os.path.join(smh_folder, 'article_level', 'corrected') #in the dataset they are reffered to as corrected but this clashes with my naming convention\n",
    "smh_articles_results = os.path.join(smh_folder, 'results')\n",
    "\n",
    "ca_folder =  os.path.join(overproof_folder, 'CA')\n",
    "ca_articles_raw = os.path.join(ca_folder, 'article_level', 'raw')\n",
    "ca_articles_transcribed = os.path.join(ca_folder, 'article_level', 'corrected') #in the dataset they are reffered to as corrected but this clashes with my naming convention\n",
    "ca_articles_results = os.path.join(ca_folder, 'results')\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv(os.path.join(dev_data_folder,'dev_data_raw.csv'))\n",
    "\n",
    "\n",
    "#for saving data to be used in the analysis\n",
    "if not os.path.exists('data/analysis'):\n",
    "    os.makedirs('data/analysis')\n",
    "\n",
    "\n",
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the test set\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create API configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the prompt/system message using the best performing from the previous section\n",
    "\n",
    "full_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. The text is from an english newspaper in the 1800's. The text may be an advert or article and may be missing the beggining or end. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "instruct_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "boros_basic  = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" +\"Correct the text\"\n",
    "\n",
    "boros_complex  =\"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"Please assist with reviewing and correcting errors in texts produced by automatic transcription (OCR) of historical documents.\n",
    "Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. \n",
    "Do not write anything else than the corrected text.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_alt_endpoint = {'alt_endpoint':{'base_url':'https://api.groq.com/openai/v1',\n",
    "                     'api_key':os.getenv(\"GROQ_API_KEY\")}}\n",
    "\n",
    "basic_model_configs = pd.DataFrame({\n",
    "    'get_response_func': [get_response_openai, get_response_openai, get_response_anthropic, get_response_anthropic, \n",
    "                          get_response_openai, get_response_openai, get_response_openai], \n",
    "    'engine': ['gpt-3.5-turbo', 'gpt-4-turbo-preview', \"claude-3-haiku-20240307\", \"claude-3-opus-20240229\", \n",
    "               'mixtral-8x7b-32768', 'llama2-70b-4096', 'gemma-7b-it'],\n",
    "    'rate_limit':[160e3, 80e3, 100e3, 40e3, 9e3, 15e3, 15e3],\n",
    "    'additional_args': [\n",
    "        {}, {}, {}, {}, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint\n",
    "    ]\n",
    "})\n",
    "\n",
    "full_model_configs = generate_model_configs(basic_model_configs, full_prompt, 'full')\n",
    "instruct_model_configs = generate_model_configs(basic_model_configs, instruct_prompt, 'instruct')\n",
    "\n",
    "#I think on reflection I only need to compare boros complex on gpt-4 as this was the best performer in their paper\n",
    "boros_configs = [\n",
    "    (get_response_openai, 'gpt-4-turbo-preview', boros_complex, \"boros_complex_\"),\n",
    "   # (get_response_openai, 'gpt-4-turbo-preview', boros_basic, \"boros_basic_\"),\n",
    "  #  (get_response_anthropic, \"claude-3-opus-20240229\", boros_complex, \"boros_complex_\")\n",
    "]\n",
    "\n",
    "boros_list = [\n",
    "    create_config_dict_func(\n",
    "        get_response_func=config[0],\n",
    "        rate_limiter=RateLimiter(80e3),\n",
    "        engine=config[1],\n",
    "        system_message_template=\"\",\n",
    "        prompt_template=config[2],\n",
    "        additional_args={\"response_name\": config[3]}\n",
    "    )\n",
    "    for config in boros_configs\n",
    "]\n",
    "\n",
    "model_configs = full_model_configs + instruct_model_configs + boros_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform all API calls\n",
    "\n",
    "The below section is what actually calls the API, the code points to the folders where the raw OCR is and provides a path to where the corrected text should be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 21:59:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:38 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:00:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:01:36 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:01:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:02:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:02:44 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:03:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:03:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:03:52 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:04:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:04:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:13 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:41 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:05:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:06:14 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:06:42 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:06:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:07:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:07:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:08:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:09:13 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:09:41 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:11:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:12:06 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:13:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:14:12 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:15:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:15:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:16:40 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:16:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:12 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:16 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:18 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:20 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:26 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:30 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:33 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:37 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:42 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:17:50 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:05 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:11 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:17 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:21 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:30 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:33 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:47 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:18:51 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:01 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:04 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:09 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:29 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:39 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:19:47 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:20:11 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:20:30 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:20:42 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:20:58 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:21:14 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:21:57 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:23:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:23:34 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:25:22 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:25:55 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:27:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:27:42 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:28:23 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:28:54 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:31:56 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:06 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:38 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:45 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:46 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:47 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:48 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:50 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:52 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:53 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:54 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:56 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:32:59 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:33:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:33:05 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:33:50 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:33:53 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:33:58 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:34:02 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:34:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:34:04 openai._base_client INFO: Retrying request to /chat/completions in 6.000000 seconds\n",
      "2024-04-22 22:34:10 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:34:10 openai._base_client INFO: Retrying request to /chat/completions in 9.000000 seconds\n",
      "2024-04-22 22:34:22 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:34:47 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:34:54 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:34:54 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:34:54 openai._base_client INFO: Retrying request to /chat/completions in 30.000000 seconds\n",
      "2024-04-22 22:35:24 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:35:24 openai._base_client INFO: Retrying request to /chat/completions in 4.000000 seconds\n",
      "2024-04-22 22:35:29 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:35:29 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:35:29 openai._base_client INFO: Retrying request to /chat/completions in 12.000000 seconds\n",
      "2024-04-22 22:35:42 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:35:42 openai._base_client INFO: Retrying request to /chat/completions in 16.000000 seconds\n",
      "2024-04-22 22:35:59 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:00 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:05 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:09 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:14 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:16 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:18 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:23 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:24 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:36:24 openai._base_client INFO: Retrying request to /chat/completions in 7.000000 seconds\n",
      "2024-04-22 22:36:36 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:36:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:36:40 openai._base_client INFO: Retrying request to /chat/completions in 15.000000 seconds\n",
      "2024-04-22 22:36:55 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:36:55 openai._base_client INFO: Retrying request to /chat/completions in 8.000000 seconds\n",
      "2024-04-22 22:37:06 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:37:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:37:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:37:11 openai._base_client INFO: Retrying request to /chat/completions in 25.000000 seconds\n",
      "2024-04-22 22:37:36 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:37:36 openai._base_client INFO: Retrying request to /chat/completions in 11.000000 seconds\n",
      "2024-04-22 22:37:53 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:37:58 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:37:58 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:37:58 openai._base_client INFO: Retrying request to /chat/completions in 8.000000 seconds\n",
      "2024-04-22 22:38:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:38:07 openai._base_client INFO: Retrying request to /chat/completions in 8.000000 seconds\n",
      "2024-04-22 22:38:20 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:20 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:38:20 openai._base_client INFO: Retrying request to /chat/completions in 1.000000 seconds\n",
      "2024-04-22 22:38:24 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:24 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:38:24 openai._base_client INFO: Retrying request to /chat/completions in 16.000000 seconds\n",
      "2024-04-22 22:38:41 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:46 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:49 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:51 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:53 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:53 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:54 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:55 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:57 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:58 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:38:59 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:01 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:39:03 openai._base_client INFO: Retrying request to /chat/completions in 9.000000 seconds\n",
      "2024-04-22 22:39:18 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:39:18 openai._base_client INFO: Retrying request to /chat/completions in 5.000000 seconds\n",
      "2024-04-22 22:39:25 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:27 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:27 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:39:27 openai._base_client INFO: Retrying request to /chat/completions in 6.000000 seconds\n",
      "2024-04-22 22:39:37 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:39 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:39:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:39:40 openai._base_client INFO: Retrying request to /chat/completions in 12.000000 seconds\n",
      "2024-04-22 22:39:52 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:39:52 openai._base_client INFO: Retrying request to /chat/completions in 8.000000 seconds\n",
      "2024-04-22 22:40:05 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:40:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:40:09 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:40:12 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:40:12 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:40:12 openai._base_client INFO: Retrying request to /chat/completions in 13.000000 seconds\n",
      "2024-04-22 22:40:26 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:40:26 openai._base_client INFO: Retrying request to /chat/completions in 37.000000 seconds\n",
      "2024-04-22 22:41:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateLimitError encountered: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma-7b-it` in organization `org_01hqwmcenrfhzv88z47c50k8fc` on tokens per minute (TPM): Limit 7500, Used 6812, Requested ~2612. Please try again in 15.387s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}, waiting for a minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:42:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:08 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:10 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:10 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 22:42:10 openai._base_client INFO: Retrying request to /chat/completions in 2.000000 seconds\n",
      "2024-04-22 22:42:13 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:40 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:42:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:43:01 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:43:09 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:43:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:44:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:44:13 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:44:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:45:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:45:53 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:46:09 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:46:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:46:44 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:47:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:47:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:48:10 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:48:12 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:48:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:48:39 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:48:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:49:13 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:49:37 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:49:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:50:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:50:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:50:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:52:13 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:52:38 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:54:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:54:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:56:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:56:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:57:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:57:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:10 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:38 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:42 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:46 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:49 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:52 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 22:59:57 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:01 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:04 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:08 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:11 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:15 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:34 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:39 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:51 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:00:55 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:01:07 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:01:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:01:22 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:01:25 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:01:59 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:01 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:06 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:07 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:27 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:36 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:02:45 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:03:13 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:03:30 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:03:47 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:04:01 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:04:17 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:04:57 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:06:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:06:34 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:08:10 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:08:44 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:10:02 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:10:33 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:11:18 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:11:44 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:14:23 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:14:34 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:05 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:11 httpx INFO: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:13 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:14 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:15 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:17 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:19 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:20 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:21 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:23 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:26 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:26 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:15:26 openai._base_client INFO: Retrying request to /chat/completions in 9.000000 seconds\n",
      "2024-04-22 23:15:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:15:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:15:40 openai._base_client INFO: Retrying request to /chat/completions in 29.000000 seconds\n",
      "2024-04-22 23:16:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:16:12 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:16:12 openai._base_client INFO: Retrying request to /chat/completions in 44.000000 seconds\n",
      "2024-04-22 23:17:01 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:17:01 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:17:01 openai._base_client INFO: Retrying request to /chat/completions in 39.000000 seconds\n",
      "2024-04-22 23:17:43 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:17:43 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:17:43 openai._base_client INFO: Retrying request to /chat/completions in 44.000000 seconds\n",
      "2024-04-22 23:18:32 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:18:32 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:18:32 openai._base_client INFO: Retrying request to /chat/completions in 36.000000 seconds\n",
      "2024-04-22 23:19:10 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:19:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:19:11 openai._base_client INFO: Retrying request to /chat/completions in 27.000000 seconds\n",
      "2024-04-22 23:19:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:19:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:19:40 openai._base_client INFO: Retrying request to /chat/completions in 21.000000 seconds\n",
      "2024-04-22 23:20:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:20:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:20:04 openai._base_client INFO: Retrying request to /chat/completions in 42.000000 seconds\n",
      "2024-04-22 23:20:50 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:20:51 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:20:56 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:20:56 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:20:56 openai._base_client INFO: Retrying request to /chat/completions in 59.000000 seconds\n",
      "2024-04-22 23:21:56 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:21:58 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:21:59 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:01 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:08 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:09 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:13 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:18 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:19 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:22:19 openai._base_client INFO: Retrying request to /chat/completions in 19.000000 seconds\n",
      "2024-04-22 23:22:45 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:22:45 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:22:45 openai._base_client INFO: Retrying request to /chat/completions in 14.000000 seconds\n",
      "2024-04-22 23:23:02 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:23:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:23:03 openai._base_client INFO: Retrying request to /chat/completions in 25.000000 seconds\n",
      "2024-04-22 23:23:30 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:23:35 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:23:35 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:23:35 openai._base_client INFO: Retrying request to /chat/completions in 33.000000 seconds\n",
      "2024-04-22 23:24:15 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:24:15 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:24:15 openai._base_client INFO: Retrying request to /chat/completions in 14.000000 seconds\n",
      "2024-04-22 23:24:32 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:24:32 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:24:32 openai._base_client INFO: Retrying request to /chat/completions in 12.000000 seconds\n",
      "2024-04-22 23:24:49 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:24:50 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:24:50 openai._base_client INFO: Retrying request to /chat/completions in 12.000000 seconds\n",
      "2024-04-22 23:25:03 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:25:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:25:04 openai._base_client INFO: Retrying request to /chat/completions in 21.000000 seconds\n",
      "2024-04-22 23:25:26 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:25:28 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:25:31 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:25:32 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:25:32 openai._base_client INFO: Retrying request to /chat/completions in 27.000000 seconds\n",
      "2024-04-22 23:26:00 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:01 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:02 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:02 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:06 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:08 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:09 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:11 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:12 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:26:12 openai._base_client INFO: Retrying request to /chat/completions in 17.000000 seconds\n",
      "2024-04-22 23:26:31 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:31 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:26:31 openai._base_client INFO: Retrying request to /chat/completions in 5.000000 seconds\n",
      "2024-04-22 23:26:38 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:26:38 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:26:38 openai._base_client INFO: Retrying request to /chat/completions in 25.000000 seconds\n",
      "2024-04-22 23:27:05 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:27:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:27:07 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:27:07 openai._base_client INFO: Retrying request to /chat/completions in 30.000000 seconds\n",
      "2024-04-22 23:27:40 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:27:41 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:27:42 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:27:42 openai._base_client INFO: Retrying request to /chat/completions in 20.000000 seconds\n",
      "2024-04-22 23:28:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:28:04 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:28:04 openai._base_client INFO: Retrying request to /chat/completions in 12.000000 seconds\n",
      "2024-04-22 23:28:17 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:28:17 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:28:17 openai._base_client INFO: Retrying request to /chat/completions in 21.000000 seconds\n",
      "2024-04-22 23:28:44 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:28:45 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:28:45 openai._base_client INFO: Retrying request to /chat/completions in 28.000000 seconds\n",
      "2024-04-22 23:29:14 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:29:14 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:29:14 openai._base_client INFO: Retrying request to /chat/completions in 6.000000 seconds\n",
      "2024-04-22 23:29:22 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:29:22 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-04-22 23:29:22 openai._base_client INFO: Retrying request to /chat/completions in 5.000000 seconds\n",
      "2024-04-22 23:29:28 httpx INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:30:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:30:37 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:30:44 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:31:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:31:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:31:37 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:32:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:32:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:32:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:33:01 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:33:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:33:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:33:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:34:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:34:46 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:36:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:36:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:38:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:39:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:40:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:41:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:42:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:42:42 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:43:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:44:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:46:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:46:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:46:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-04-22 23:46:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "corrected_folder = ncse_articles_results\n",
    "#\n",
    "# This naming business needs to be cleaned up so the actual article ID is used. until then just have the following mess\n",
    "#\n",
    "# \n",
    "\n",
    "test_data_new = pd.read_csv(os.path.join(dev_data_folder,'transcription_raw_ocr.csv'))\n",
    "test_data_new = test_data_new.loc[test_data_new ['file_name'].isin(files_to_df_func(ncse_articles_transcribed )['file_name'])] #subset to just the data I have transcribed\n",
    "\n",
    "#This goes through the list of articles that have been transcribed, checks to see if there is a corrected version and if not generates it\n",
    "compare_request_configurations(test_data_new, model_configs, folder_path=corrected_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boros etal re-evaluation\n",
    "\n",
    "The post-OCR correction worked so well that the Boros etal prompt is being re-evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boros_complex  =\"{content}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"Please assist with reviewing and correcting errors in texts produced by automatic transcription (OCR) of historical documents.\n",
    "Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. \n",
    "Do not write anything else than the corrected text.\"\"\"\n",
    "\n",
    "\n",
    "boros_config = generate_model_configs(basic_model_configs.iloc[0:2, :], boros_complex, 'boros_complex_')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sydney Morning Herald\n",
    "\n",
    "This section performs the correction test on dataset 2 of the Overproof collection. This is data from the Sydney Morning Herald. In addition it re-tests the Boros et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smh_data = files_to_df_core_func(smh_articles_raw )\n",
    "\n",
    "smh_data['content'] = smh_data['content'].str.replace('\\n', ' ')\n",
    "\n",
    "smh_data['id'] = smh_data['file_name'] # this is needed as the processing log uses an id to keep track of what has been processed and what hasn't to allow for easy restarts\n",
    "\n",
    "full_prompt_smh = \"{content}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. The text is from The Sydney Morning Herald 1842 -1950. The text may be an advert or article and may be missing the beggining or end. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "instruct_prompt_smh = \"{content}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "full_model_configs_smh = generate_model_configs(basic_model_configs, full_prompt_smh, 'full')\n",
    "instruct_model_configs_smh = generate_model_configs(basic_model_configs, instruct_prompt_smh, 'instruct')\n",
    "\n",
    "#Boros et al prompt added in as the overall system works so well, it seems strange theirs didn't work, this is a quick check\n",
    "smh_configs = full_model_configs_smh + instruct_model_configs_smh  + [boros_config ]\n",
    "\n",
    "corrected_folder_smh = smh_articles_results\n",
    "\n",
    "compare_request_configurations(smh_data, smh_configs, folder_path=corrected_folder_smh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronicalling America\n",
    "\n",
    "This section performs the correction test on dataset 2 of the Overproof collection. This is data from the Chronicalling America Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_data = files_to_df_core_func(ca_articles_raw )\n",
    "\n",
    "ca_data['content'] = ca_data['content'].str.replace('\\n', ' ')\n",
    "\n",
    "ca_data['id'] = ca_data['file_name'] # this is needed as the processing log uses an id to keep track of what has been processed and what hasn't to allow for easy restarts\n",
    "\n",
    "full_prompt_ca = \"{content}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. The text is from American Newspapers 1870 -1922. The text may be an advert or article and may be missing the beggining or end. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "instruct_prompt_ca = \"{content}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "\n",
    "full_model_configs_ca = generate_model_configs(basic_model_configs, full_prompt_ca, 'full')\n",
    "instruct_model_configs_ca = generate_model_configs(basic_model_configs, instruct_prompt_ca, 'instruct')\n",
    "\n",
    "ca_configs = full_model_configs_ca + instruct_model_configs_ca  + [boros_config ]\n",
    "\n",
    "corrected_folder_ca = ca_articles_results\n",
    "\n",
    "compare_request_configurations(ca_data, ca_configs, folder_path=corrected_folder_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the prompts across all models\n",
    "\n",
    "On the smaller models, Full is worse than instruct on the larger models the reverse. Maybe this is related to ability to 'focus' or hold isntructions in memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <td>-15.54</td>\n",
       "      <td>-16.89</td>\n",
       "      <td>-518.93</td>\n",
       "      <td>-438.49</td>\n",
       "      <td>-505.81</td>\n",
       "      <td>-425.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-haiku-20240307</th>\n",
       "      <td>7.66</td>\n",
       "      <td>4.38</td>\n",
       "      <td>-451.43</td>\n",
       "      <td>-416.94</td>\n",
       "      <td>-440.49</td>\n",
       "      <td>-404.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-haiku-20240307</th>\n",
       "      <td>-1.91</td>\n",
       "      <td>9.95</td>\n",
       "      <td>-540.02</td>\n",
       "      <td>-400.21</td>\n",
       "      <td>-527.16</td>\n",
       "      <td>-388.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <td>-8.95</td>\n",
       "      <td>3.95</td>\n",
       "      <td>-527.45</td>\n",
       "      <td>-366.23</td>\n",
       "      <td>-514.25</td>\n",
       "      <td>-355.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <td>25.01</td>\n",
       "      <td>39.03</td>\n",
       "      <td>-180.88</td>\n",
       "      <td>-160.83</td>\n",
       "      <td>-174.98</td>\n",
       "      <td>-157.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <td>25.15</td>\n",
       "      <td>26.37</td>\n",
       "      <td>-159.35</td>\n",
       "      <td>-157.87</td>\n",
       "      <td>-154.51</td>\n",
       "      <td>-151.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <td>39.17</td>\n",
       "      <td>49.56</td>\n",
       "      <td>-63.93</td>\n",
       "      <td>-60.52</td>\n",
       "      <td>-63.22</td>\n",
       "      <td>-59.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <td>21.83</td>\n",
       "      <td>38.78</td>\n",
       "      <td>-267.23</td>\n",
       "      <td>-54.36</td>\n",
       "      <td>-259.58</td>\n",
       "      <td>-53.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <td>-208.80</td>\n",
       "      <td>58.62</td>\n",
       "      <td>-667.16</td>\n",
       "      <td>-28.81</td>\n",
       "      <td>-653.78</td>\n",
       "      <td>-29.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_basic__gpt-4-turbo-preview</th>\n",
       "      <td>83.78</td>\n",
       "      <td>86.07</td>\n",
       "      <td>71.34</td>\n",
       "      <td>70.93</td>\n",
       "      <td>67.55</td>\n",
       "      <td>66.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <td>84.36</td>\n",
       "      <td>85.97</td>\n",
       "      <td>74.95</td>\n",
       "      <td>76.62</td>\n",
       "      <td>71.46</td>\n",
       "      <td>72.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <td>82.29</td>\n",
       "      <td>82.31</td>\n",
       "      <td>72.06</td>\n",
       "      <td>77.33</td>\n",
       "      <td>68.58</td>\n",
       "      <td>73.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <td>39.50</td>\n",
       "      <td>82.81</td>\n",
       "      <td>-35.65</td>\n",
       "      <td>80.65</td>\n",
       "      <td>-36.22</td>\n",
       "      <td>76.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__gpt-4-turbo-preview</th>\n",
       "      <td>82.49</td>\n",
       "      <td>83.42</td>\n",
       "      <td>73.19</td>\n",
       "      <td>81.26</td>\n",
       "      <td>69.75</td>\n",
       "      <td>76.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <td>81.98</td>\n",
       "      <td>83.68</td>\n",
       "      <td>73.73</td>\n",
       "      <td>85.42</td>\n",
       "      <td>69.79</td>\n",
       "      <td>80.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <td>83.66</td>\n",
       "      <td>84.74</td>\n",
       "      <td>76.27</td>\n",
       "      <td>86.01</td>\n",
       "      <td>72.21</td>\n",
       "      <td>80.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       WER            CER         lev_dist  \\\n",
       "                                      mean    50%    mean     50%     mean   \n",
       "type                                                                         \n",
       "full__gemma-7b-it                   -15.54 -16.89 -518.93 -438.49  -505.81   \n",
       "instruct__claude-3-haiku-20240307     7.66   4.38 -451.43 -416.94  -440.49   \n",
       "full__claude-3-haiku-20240307        -1.91   9.95 -540.02 -400.21  -527.16   \n",
       "instruct__gemma-7b-it                -8.95   3.95 -527.45 -366.23  -514.25   \n",
       "instruct__mixtral-8x7b-32768         25.01  39.03 -180.88 -160.83  -174.98   \n",
       "full__mixtral-8x7b-32768             25.15  26.37 -159.35 -157.87  -154.51   \n",
       "instruct__llama2-70b-4096            39.17  49.56  -63.93  -60.52   -63.22   \n",
       "full__gpt-3.5-turbo                  21.83  38.78 -267.23  -54.36  -259.58   \n",
       "full__llama2-70b-4096              -208.80  58.62 -667.16  -28.81  -653.78   \n",
       "boros_basic__gpt-4-turbo-preview     83.78  86.07   71.34   70.93    67.55   \n",
       "instruct__gpt-4-turbo-preview        84.36  85.97   74.95   76.62    71.46   \n",
       "full__gpt-4-turbo-preview            82.29  82.31   72.06   77.33    68.58   \n",
       "instruct__gpt-3.5-turbo              39.50  82.81  -35.65   80.65   -36.22   \n",
       "boros_complex__gpt-4-turbo-preview   82.49  83.42   73.19   81.26    69.75   \n",
       "full__claude-3-opus-20240229         81.98  83.68   73.73   85.42    69.79   \n",
       "instruct__claude-3-opus-20240229     83.66  84.74   76.27   86.01    72.21   \n",
       "\n",
       "                                            \n",
       "                                       50%  \n",
       "type                                        \n",
       "full__gemma-7b-it                  -425.19  \n",
       "instruct__claude-3-haiku-20240307  -404.33  \n",
       "full__claude-3-haiku-20240307      -388.23  \n",
       "instruct__gemma-7b-it              -355.19  \n",
       "instruct__mixtral-8x7b-32768       -157.34  \n",
       "full__mixtral-8x7b-32768           -151.92  \n",
       "instruct__llama2-70b-4096           -59.65  \n",
       "full__gpt-3.5-turbo                 -53.77  \n",
       "full__llama2-70b-4096               -29.68  \n",
       "boros_basic__gpt-4-turbo-preview     66.11  \n",
       "instruct__gpt-4-turbo-preview        72.75  \n",
       "full__gpt-4-turbo-preview            73.43  \n",
       "instruct__gpt-3.5-turbo              76.66  \n",
       "boros_complex__gpt-4-turbo-preview   76.76  \n",
       "full__claude-3-opus-20240229         80.09  \n",
       "instruct__claude-3-opus-20240229     80.65  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## double check get_metric_error_reduction\n",
    "##\n",
    "\n",
    "corrected_folder = ncse_articles_results \n",
    "\n",
    "gt_folder = ncse_articles_transcribed \n",
    "\n",
    "raw_ocr = ncse_articles_raw\n",
    "\n",
    "ncse_performance_eval =  evaluate_correction_performance_folders(corrected_folder, gt_folder, wer, cer)\n",
    "\n",
    "ncse_raw_ocr_eval =  evaluate_correction_performance(raw_ocr, gt_folder , wer, cer, 'raw_ocr')\n",
    "\n",
    "\n",
    "ncse_error_reduction = get_metric_error_reduction(ncse_performance_eval, ncse_raw_ocr_eval )\n",
    "\n",
    "ncse_error_reduction.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <td>-9.43</td>\n",
       "      <td>3.26</td>\n",
       "      <td>-227.08</td>\n",
       "      <td>-35.65</td>\n",
       "      <td>-225.59</td>\n",
       "      <td>-35.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <td>13.60</td>\n",
       "      <td>17.39</td>\n",
       "      <td>-73.26</td>\n",
       "      <td>-19.11</td>\n",
       "      <td>-73.68</td>\n",
       "      <td>-20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <td>13.40</td>\n",
       "      <td>18.00</td>\n",
       "      <td>-58.17</td>\n",
       "      <td>-14.63</td>\n",
       "      <td>-59.16</td>\n",
       "      <td>-15.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <td>2.66</td>\n",
       "      <td>9.66</td>\n",
       "      <td>-161.36</td>\n",
       "      <td>-12.93</td>\n",
       "      <td>-160.68</td>\n",
       "      <td>-13.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <td>0.68</td>\n",
       "      <td>16.67</td>\n",
       "      <td>-43.20</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-45.81</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <td>-2.28</td>\n",
       "      <td>16.00</td>\n",
       "      <td>-44.03</td>\n",
       "      <td>6.45</td>\n",
       "      <td>-46.28</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overproof</th>\n",
       "      <td>19.38</td>\n",
       "      <td>19.23</td>\n",
       "      <td>27.28</td>\n",
       "      <td>28.38</td>\n",
       "      <td>25.83</td>\n",
       "      <td>27.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-haiku-20240307</th>\n",
       "      <td>21.35</td>\n",
       "      <td>26.92</td>\n",
       "      <td>-48.01</td>\n",
       "      <td>35.71</td>\n",
       "      <td>-47.86</td>\n",
       "      <td>33.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-haiku-20240307</th>\n",
       "      <td>21.58</td>\n",
       "      <td>27.34</td>\n",
       "      <td>-40.65</td>\n",
       "      <td>38.38</td>\n",
       "      <td>-40.69</td>\n",
       "      <td>37.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <td>25.34</td>\n",
       "      <td>26.72</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>39.18</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>38.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <td>29.88</td>\n",
       "      <td>30.20</td>\n",
       "      <td>32.09</td>\n",
       "      <td>41.79</td>\n",
       "      <td>31.60</td>\n",
       "      <td>41.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <td>30.15</td>\n",
       "      <td>30.00</td>\n",
       "      <td>32.65</td>\n",
       "      <td>42.08</td>\n",
       "      <td>31.98</td>\n",
       "      <td>41.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <td>27.18</td>\n",
       "      <td>27.75</td>\n",
       "      <td>28.45</td>\n",
       "      <td>42.86</td>\n",
       "      <td>28.13</td>\n",
       "      <td>41.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <td>30.96</td>\n",
       "      <td>32.72</td>\n",
       "      <td>36.15</td>\n",
       "      <td>45.45</td>\n",
       "      <td>32.12</td>\n",
       "      <td>41.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex___gpt-4-turbo-preview</th>\n",
       "      <td>30.20</td>\n",
       "      <td>30.71</td>\n",
       "      <td>44.01</td>\n",
       "      <td>48.44</td>\n",
       "      <td>43.46</td>\n",
       "      <td>48.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <td>31.39</td>\n",
       "      <td>32.11</td>\n",
       "      <td>45.92</td>\n",
       "      <td>51.03</td>\n",
       "      <td>41.79</td>\n",
       "      <td>48.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       WER            CER        lev_dist  \\\n",
       "                                      mean    50%    mean    50%     mean   \n",
       "type                                                                        \n",
       "full__gemma-7b-it                    -9.43   3.26 -227.08 -35.65  -225.59   \n",
       "instruct__mixtral-8x7b-32768         13.60  17.39  -73.26 -19.11   -73.68   \n",
       "full__mixtral-8x7b-32768             13.40  18.00  -58.17 -14.63   -59.16   \n",
       "instruct__gemma-7b-it                 2.66   9.66 -161.36 -12.93  -160.68   \n",
       "full__llama2-70b-4096                 0.68  16.67  -43.20   5.77   -45.81   \n",
       "instruct__llama2-70b-4096            -2.28  16.00  -44.03   6.45   -46.28   \n",
       "overproof                            19.38  19.23   27.28  28.38    25.83   \n",
       "instruct__claude-3-haiku-20240307    21.35  26.92  -48.01  35.71   -47.86   \n",
       "full__claude-3-haiku-20240307        21.58  27.34  -40.65  38.38   -40.69   \n",
       "full__gpt-3.5-turbo                  25.34  26.72   -0.52  39.18    -0.34   \n",
       "instruct__gpt-4-turbo-preview        29.88  30.20   32.09  41.79    31.60   \n",
       "full__gpt-4-turbo-preview            30.15  30.00   32.65  42.08    31.98   \n",
       "instruct__gpt-3.5-turbo              27.18  27.75   28.45  42.86    28.13   \n",
       "instruct__claude-3-opus-20240229     30.96  32.72   36.15  45.45    32.12   \n",
       "boros_complex___gpt-4-turbo-preview  30.20  30.71   44.01  48.44    43.46   \n",
       "full__claude-3-opus-20240229         31.39  32.11   45.92  51.03    41.79   \n",
       "\n",
       "                                            \n",
       "                                       50%  \n",
       "type                                        \n",
       "full__gemma-7b-it                   -35.34  \n",
       "instruct__mixtral-8x7b-32768        -20.00  \n",
       "full__mixtral-8x7b-32768            -15.24  \n",
       "instruct__gemma-7b-it               -13.04  \n",
       "full__llama2-70b-4096                 1.85  \n",
       "instruct__llama2-70b-4096             3.08  \n",
       "overproof                            27.59  \n",
       "instruct__claude-3-haiku-20240307    33.80  \n",
       "full__claude-3-haiku-20240307        37.48  \n",
       "full__gpt-3.5-turbo                  38.66  \n",
       "instruct__gpt-4-turbo-preview        41.18  \n",
       "full__gpt-4-turbo-preview            41.46  \n",
       "instruct__gpt-3.5-turbo              41.46  \n",
       "instruct__claude-3-opus-20240229     41.57  \n",
       "boros_complex___gpt-4-turbo-preview  48.23  \n",
       "full__claude-3-opus-20240229         48.78  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_folder = smh_articles_results \n",
    "\n",
    "gt_folder = smh_articles_transcribed \n",
    "\n",
    "raw_ocr = smh_articles_raw\n",
    "\n",
    "smh_performance_eval =  evaluate_correction_performance_folders(corrected_folder, gt_folder, wer, cer)\n",
    "\n",
    "smh_raw_ocr_eval =  evaluate_correction_performance(raw_ocr, gt_folder , wer, cer, 'raw_ocr')\n",
    "\n",
    "smh_error_reduction = get_metric_error_reduction(smh_performance_eval, smh_raw_ocr_eval )\n",
    "\n",
    "smh_error_reduction.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <td>-0.83</td>\n",
       "      <td>5.66</td>\n",
       "      <td>-154.39</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>-153.98</td>\n",
       "      <td>-42.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <td>-5.28</td>\n",
       "      <td>3.04</td>\n",
       "      <td>-209.20</td>\n",
       "      <td>-38.01</td>\n",
       "      <td>-208.30</td>\n",
       "      <td>-38.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <td>7.89</td>\n",
       "      <td>13.72</td>\n",
       "      <td>-71.77</td>\n",
       "      <td>-22.07</td>\n",
       "      <td>-72.00</td>\n",
       "      <td>-22.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <td>8.66</td>\n",
       "      <td>15.72</td>\n",
       "      <td>-60.65</td>\n",
       "      <td>-16.30</td>\n",
       "      <td>-60.94</td>\n",
       "      <td>-14.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.19</td>\n",
       "      <td>-35.66</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-38.95</td>\n",
       "      <td>-8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <td>7.72</td>\n",
       "      <td>10.86</td>\n",
       "      <td>-45.09</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-46.74</td>\n",
       "      <td>-7.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-haiku-20240307</th>\n",
       "      <td>8.15</td>\n",
       "      <td>14.97</td>\n",
       "      <td>-92.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>-92.22</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overproof</th>\n",
       "      <td>20.64</td>\n",
       "      <td>21.63</td>\n",
       "      <td>34.11</td>\n",
       "      <td>34.59</td>\n",
       "      <td>34.01</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-haiku-20240307</th>\n",
       "      <td>9.48</td>\n",
       "      <td>17.41</td>\n",
       "      <td>-91.40</td>\n",
       "      <td>34.73</td>\n",
       "      <td>-91.28</td>\n",
       "      <td>34.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <td>22.64</td>\n",
       "      <td>20.98</td>\n",
       "      <td>33.74</td>\n",
       "      <td>37.57</td>\n",
       "      <td>33.23</td>\n",
       "      <td>37.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <td>22.12</td>\n",
       "      <td>21.84</td>\n",
       "      <td>29.70</td>\n",
       "      <td>38.18</td>\n",
       "      <td>28.86</td>\n",
       "      <td>37.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <td>24.90</td>\n",
       "      <td>24.26</td>\n",
       "      <td>41.26</td>\n",
       "      <td>47.01</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <td>24.74</td>\n",
       "      <td>24.61</td>\n",
       "      <td>43.51</td>\n",
       "      <td>48.23</td>\n",
       "      <td>40.76</td>\n",
       "      <td>43.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <td>19.48</td>\n",
       "      <td>22.90</td>\n",
       "      <td>-18.29</td>\n",
       "      <td>44.22</td>\n",
       "      <td>-18.35</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <td>25.64</td>\n",
       "      <td>24.62</td>\n",
       "      <td>41.21</td>\n",
       "      <td>44.05</td>\n",
       "      <td>40.96</td>\n",
       "      <td>44.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex___gpt-4-turbo-preview</th>\n",
       "      <td>24.61</td>\n",
       "      <td>24.02</td>\n",
       "      <td>44.23</td>\n",
       "      <td>45.55</td>\n",
       "      <td>43.95</td>\n",
       "      <td>45.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       WER            CER        lev_dist  \\\n",
       "                                      mean    50%    mean    50%     mean   \n",
       "type                                                                        \n",
       "instruct__gemma-7b-it                -0.83   5.66 -154.39 -41.00  -153.98   \n",
       "full__gemma-7b-it                    -5.28   3.04 -209.20 -38.01  -208.30   \n",
       "instruct__mixtral-8x7b-32768          7.89  13.72  -71.77 -22.07   -72.00   \n",
       "full__mixtral-8x7b-32768              8.66  15.72  -60.65 -16.30   -60.94   \n",
       "full__llama2-70b-4096                10.00  10.19  -35.66  -4.90   -38.95   \n",
       "instruct__llama2-70b-4096             7.72  10.86  -45.09  -6.48   -46.74   \n",
       "full__claude-3-haiku-20240307         8.15  14.97  -92.14  26.01   -92.22   \n",
       "overproof                            20.64  21.63   34.11  34.59    34.01   \n",
       "instruct__claude-3-haiku-20240307     9.48  17.41  -91.40  34.73   -91.28   \n",
       "instruct__gpt-4-turbo-preview        22.64  20.98   33.74  37.57    33.23   \n",
       "full__gpt-4-turbo-preview            22.12  21.84   29.70  38.18    28.86   \n",
       "instruct__claude-3-opus-20240229     24.90  24.26   41.26  47.01    38.70   \n",
       "full__claude-3-opus-20240229         24.74  24.61   43.51  48.23    40.76   \n",
       "full__gpt-3.5-turbo                  19.48  22.90  -18.29  44.22   -18.35   \n",
       "instruct__gpt-3.5-turbo              25.64  24.62   41.21  44.05    40.96   \n",
       "boros_complex___gpt-4-turbo-preview  24.61  24.02   44.23  45.55    43.95   \n",
       "\n",
       "                                            \n",
       "                                       50%  \n",
       "type                                        \n",
       "instruct__gemma-7b-it               -42.38  \n",
       "full__gemma-7b-it                   -38.15  \n",
       "instruct__mixtral-8x7b-32768        -22.36  \n",
       "full__mixtral-8x7b-32768            -14.86  \n",
       "full__llama2-70b-4096                -8.14  \n",
       "instruct__llama2-70b-4096            -7.94  \n",
       "full__claude-3-haiku-20240307        25.27  \n",
       "overproof                            34.59  \n",
       "instruct__claude-3-haiku-20240307    34.73  \n",
       "instruct__gpt-4-turbo-preview        37.45  \n",
       "full__gpt-4-turbo-preview            37.70  \n",
       "instruct__claude-3-opus-20240229     41.18  \n",
       "full__claude-3-opus-20240229         43.44  \n",
       "full__gpt-3.5-turbo                  43.99  \n",
       "instruct__gpt-3.5-turbo              44.05  \n",
       "boros_complex___gpt-4-turbo-preview  45.19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_folder = ca_articles_results \n",
    "\n",
    "gt_folder = ca_articles_transcribed \n",
    "\n",
    "raw_ocr = ca_articles_raw\n",
    "\n",
    "ca_performance_eval =  evaluate_correction_performance_folders(corrected_folder, gt_folder, wer, cer)\n",
    "\n",
    "ca_raw_ocr_eval =  evaluate_correction_performance(raw_ocr, gt_folder , wer, cer, 'raw_ocr')\n",
    "\n",
    "ca_error_reduction = get_metric_error_reduction(ca_performance_eval, ca_raw_ocr_eval )\n",
    "\n",
    "ca_error_reduction.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>NCSE</th>\n",
       "      <th>SMH</th>\n",
       "      <th>CA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>full__gemma-7b-it</td>\n",
       "      <td>-425.19</td>\n",
       "      <td>-35.34</td>\n",
       "      <td>-38.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>instruct__claude-3-haiku-20240307</td>\n",
       "      <td>-404.33</td>\n",
       "      <td>33.80</td>\n",
       "      <td>34.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full__claude-3-haiku-20240307</td>\n",
       "      <td>-388.23</td>\n",
       "      <td>37.48</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>instruct__gemma-7b-it</td>\n",
       "      <td>-355.19</td>\n",
       "      <td>-13.04</td>\n",
       "      <td>-42.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>instruct__mixtral-8x7b-32768</td>\n",
       "      <td>-157.34</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-22.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>full__mixtral-8x7b-32768</td>\n",
       "      <td>-151.92</td>\n",
       "      <td>-15.24</td>\n",
       "      <td>-14.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>instruct__llama2-70b-4096</td>\n",
       "      <td>-59.65</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-7.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>full__gpt-3.5-turbo</td>\n",
       "      <td>-53.77</td>\n",
       "      <td>38.66</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full__llama2-70b-4096</td>\n",
       "      <td>-29.68</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>instruct__gpt-4-turbo-preview</td>\n",
       "      <td>72.75</td>\n",
       "      <td>41.18</td>\n",
       "      <td>37.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>full__gpt-4-turbo-preview</td>\n",
       "      <td>73.43</td>\n",
       "      <td>41.46</td>\n",
       "      <td>37.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>instruct__gpt-3.5-turbo</td>\n",
       "      <td>76.66</td>\n",
       "      <td>41.46</td>\n",
       "      <td>44.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boros_complex__gpt-4-turbo-preview</td>\n",
       "      <td>76.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full__claude-3-opus-20240229</td>\n",
       "      <td>80.09</td>\n",
       "      <td>48.78</td>\n",
       "      <td>43.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>instruct__claude-3-opus-20240229</td>\n",
       "      <td>80.65</td>\n",
       "      <td>41.57</td>\n",
       "      <td>41.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boros_complex___gpt-4-turbo-preview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.23</td>\n",
       "      <td>45.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>overproof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.59</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   type    NCSE    SMH     CA\n",
       "5                     full__gemma-7b-it -425.19 -35.34 -38.15\n",
       "10    instruct__claude-3-haiku-20240307 -404.33  33.80  34.73\n",
       "3         full__claude-3-haiku-20240307 -388.23  37.48  25.27\n",
       "12                instruct__gemma-7b-it -355.19 -13.04 -42.38\n",
       "16         instruct__mixtral-8x7b-32768 -157.34 -20.00 -22.36\n",
       "9              full__mixtral-8x7b-32768 -151.92 -15.24 -14.86\n",
       "15            instruct__llama2-70b-4096  -59.65   3.08  -7.94\n",
       "6                   full__gpt-3.5-turbo  -53.77  38.66  43.99\n",
       "8                 full__llama2-70b-4096  -29.68   1.85  -8.14\n",
       "14        instruct__gpt-4-turbo-preview   72.75  41.18  37.45\n",
       "7             full__gpt-4-turbo-preview   73.43  41.46  37.70\n",
       "13              instruct__gpt-3.5-turbo   76.66  41.46  44.05\n",
       "2    boros_complex__gpt-4-turbo-preview   76.76    NaN    NaN\n",
       "4          full__claude-3-opus-20240229   80.09  48.78  43.44\n",
       "11     instruct__claude-3-opus-20240229   80.65  41.57  41.18\n",
       "1   boros_complex___gpt-4-turbo-preview     NaN  48.23  45.19\n",
       "17                            overproof     NaN  27.59  34.59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncse_median = ncse_error_reduction.groupby('type')['lev_dist'].median().round(2)\n",
    "smh_median = smh_error_reduction.groupby('type')['lev_dist'].median().round(2)\n",
    "ca_median = ca_error_reduction.groupby('type')['lev_dist'].median().round(2)\n",
    "\n",
    "# Combine the results into a new dataframe\n",
    "result_df = pd.DataFrame({\n",
    "    'NCSE': ncse_median,\n",
    "    'SMH': smh_median,\n",
    "    'CA': ca_median\n",
    "})\n",
    "\n",
    "# Reset the index to make 'type' a regular column\n",
    "result_df = result_df.reset_index()\n",
    "\n",
    "result_df = result_df.loc[~result_df['type'].isin(['boros_basic__gpt-4-turbo-preview',  'claude_temp_claude-3-opus-20240229'])]\n",
    "\n",
    "result_df.sort_values('NCSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
